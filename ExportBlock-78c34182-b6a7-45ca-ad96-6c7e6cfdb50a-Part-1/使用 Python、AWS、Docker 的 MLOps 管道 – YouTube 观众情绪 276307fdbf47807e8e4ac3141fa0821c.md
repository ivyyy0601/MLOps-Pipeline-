# ä½¿ç”¨ Pythonã€AWSã€Docker çš„ MLOps ç®¡é“ â€“ YouTube è§‚ä¼—æƒ…ç»ª

1. **Data collection**
    
    â†’ æ•°æ®æ”¶é›†ï¼šé€šè¿‡ APIã€æ•°æ®åº“ã€CSV æ–‡ä»¶ç­‰æ–¹å¼è·å–åŸå§‹æ•°æ®ã€‚
    
2. **Data preprocessing and EDA**
    
    â†’ æ•°æ®é¢„å¤„ç†å’Œæ¢ç´¢æ€§æ•°æ®åˆ†æ (Exploratory Data Analysis)ï¼šæ¸…æ´—æ•°æ®ã€å¤„ç†ç¼ºå¤±å€¼/å¼‚å¸¸å€¼ã€ç‰¹å¾å·¥ç¨‹ï¼Œä»¥åŠå¯¹æ•°æ®è¿›è¡Œå¯è§†åŒ–å’Œç»Ÿè®¡åˆ†æã€‚
    
3. **Building Baseline Model**
    
    â†’ å»ºç«‹åŸºçº¿æ¨¡å‹ï¼šå…ˆç”¨æœ€ç®€å•çš„æ¨¡å‹ï¼ˆå¦‚ Logistic Regressionã€Random Forestã€TF-IDF + åˆ†ç±»å™¨ï¼‰è·‘ä¸€ä¸ªåˆå§‹ç‰ˆæœ¬ï¼Œä½œä¸ºåç»­ä¼˜åŒ–çš„å‚è€ƒæ ‡å‡†ã€‚
    
4. **Setup MLflow server on AWS**
    
    â†’ åœ¨ AWS ä¸Šæ­å»ºÂ **MLflow æœåŠ¡å™¨**ï¼šç”¨äºç®¡ç†æœºå™¨å­¦ä¹ å®éªŒï¼ŒåŒ…æ‹¬æ¨¡å‹è®­ç»ƒæ—¥å¿—ã€å‚æ•°ã€æŒ‡æ ‡ã€æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ç­‰ã€‚
    
5. **improve Baseline Model**
    
    â†’ åœ¨ NLP ä»»åŠ¡é‡Œï¼ŒåŸºçº¿ä¸€èˆ¬æ˜¯ç”¨ Bag-of-Words (BoW) æˆ– TF-IDF ç‰¹å¾ + é€»è¾‘å›å½’ / SVM / Naive Bayes åšåˆ†ç±»ã€‚æ¥ä¸‹æ¥çš„æ­¥éª¤å°±æ˜¯åœ¨è¿™ä¸ªåŸºçº¿åŸºç¡€ä¸Šæ”¹è¿›ã€‚
    
    - **BoW, TF-IDF**
        
        â†’ æœ€åŸºç¡€çš„æ–‡æœ¬ç‰¹å¾æå–æ–¹æ³•ï¼ŒæŠŠæ–‡æœ¬è½¬æˆè¯é¢‘çŸ©é˜µæˆ–åŠ æƒçŸ©é˜µã€‚
        
    - **Max Features**
        
        â†’ é™åˆ¶ç‰¹å¾æ•°é‡ï¼ˆæ¯”å¦‚å–å‰ 5,000 ä¸ªè¯ï¼‰ï¼Œå‡å°‘ç»´åº¦ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚
        
    - **Handling Imbalanced Data**
        
        â†’ å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œæ¯”å¦‚ï¼š
        
        - ä½¿ç”¨Â **SMOTE**Â åšè¿‡é‡‡æ ·
        - ä½¿ç”¨Â **class weights**Â è°ƒæ•´æŸå¤±å‡½æ•°
        - ä¸‹é‡‡æ ·å¤šæ•°ç±»
    - **Hyperparameter Tuning with Multiple ML Models**
        
        â†’ è°ƒä¸åŒæ¨¡å‹ï¼ˆLogistic Regression, Random Forest, XGBoost, SVMï¼‰ï¼Œå¹¶é€šè¿‡ç½‘æ ¼æœç´¢ (Grid Search) æˆ–éšæœºæœç´¢ (Random Search) æ¥æ‰¾åˆ°æœ€ä¼˜å‚æ•°ã€‚
        
    - **Stacking Model**
        
        â†’ æ¨¡å‹é›†æˆ (Ensemble Learning) æŠ€æœ¯ä¹‹ä¸€ï¼ŒæŠŠå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœä½œä¸ºæ–°ç‰¹å¾ï¼Œå†è®­ç»ƒä¸€ä¸ªâ€œå…ƒæ¨¡å‹â€ (meta-model) æ¥æé«˜æ€§èƒ½ã€‚
        
    
6. **Build ML pipeline using DVC**

â†’ ç”¨Â **DVC (Data Version Control)**Â æ­å»ºæœºå™¨å­¦ä¹ æµæ°´çº¿ï¼Œç”¨äºæ•°æ®ç‰ˆæœ¬ç®¡ç†ã€ç‰¹å¾å¤„ç†ã€è®­ç»ƒæµç¨‹è‡ªåŠ¨åŒ–ã€‚

1. **Add model to model registry**
    
    â†’ æŠŠè®­ç»ƒå¥½çš„æ¨¡å‹åŠ å…¥Â **æ¨¡å‹æ³¨å†Œåº“ (Model Registry)**ï¼Œä¾¿äºç‰ˆæœ¬ç®¡ç†ã€å›æ»šã€éƒ¨ç½²ã€‚å¸¸è§å·¥å…·ï¼šMLflowã€Sagemakerã€Kubeflowã€‚
    
2. **Implement Chrome plugin**
    
    â†’ å¼€å‘ä¸€ä¸ªÂ **Chrome æ’ä»¶**ï¼ŒæŠŠæ¨¡å‹çš„é¢„æµ‹åŠŸèƒ½åµŒå…¥åˆ°æµè§ˆå™¨æ’ä»¶ä¸­ï¼Œä½œä¸ºç”¨æˆ·ç«¯çš„äº¤äº’ç•Œé¢ã€‚
    
3. **CI/CD workflow**
    
    â†’ å»ºç«‹æŒç»­é›†æˆ / æŒç»­éƒ¨ç½² (CI/CD) å·¥ä½œæµï¼Œä¾‹å¦‚ç”¨ GitHub Actionsã€Jenkins æˆ– GitLab CIï¼ŒæŠŠä»£ç æ›´æ–°ã€æ¨¡å‹è®­ç»ƒã€æµ‹è¯•å’Œä¸Šçº¿è‡ªåŠ¨åŒ–ã€‚
    
4. **Dockerization**
    
    â†’ ç”¨**Docker**æŠŠæ¨¡å‹å’Œä¾èµ–ç¯å¢ƒæ‰“åŒ…ï¼Œä¿è¯åœ¨ä¸åŒç¯å¢ƒé‡Œéƒ½èƒ½ä¸€è‡´è¿è¡Œã€‚
    
5. **Deployment â€“ AWS**
    
    â†’ æŠŠæ¨¡å‹éƒ¨ç½²åˆ°**AWS**ï¼ˆæ¯”å¦‚ EC2ã€SageMakerã€ECSã€Lambdaï¼‰ï¼Œè®©å®ƒå¯¹å¤–æä¾› API æˆ–æœåŠ¡ã€‚
    
6. **GitHub**
    
    â†’ ç”¨ GitHub ç®¡ç†é¡¹ç›®ä»£ç ï¼Œåšç‰ˆæœ¬æ§åˆ¶ã€åä½œå’Œå¼€æºã€‚
    

1. **Data collection**
    1. å¤„ç†ç›´æ¥å»æ‰nulå€¼å’Œduplicateæ•°å€¼
    2. å¤šä½™çš„é¦–å°¾ç©ºæ ¼åœ¨Â **åˆ†è¯(tokenization)**Â æˆ–Â **å‘é‡åŒ–(æ¯”å¦‚ TF-IDF, Word2Vec)**Â æ—¶ä¼šé€ æˆ â€œå‡ç‰¹å¾â€ã€‚ä¸¾ä¾‹ï¼š
        
        `"apple "`Â å’ŒÂ `"apple"`Â åœ¨æ²¡æ¸…æ´—ä¹‹å‰ä¼šè¢«å½“æˆä¸¤ä¸ªä¸åŒçš„ tokenã€‚
        
        è¿™æ ·ä¼šè®©è¯è¡¨å˜å¾—æ··ä¹±ï¼Œå¢åŠ å™ªå£°ï¼Œå½±å“æ¨¡å‹æ•ˆæœã€‚
        
    3. 
    - **ç»Ÿä¸€æ ¼å¼**ï¼ˆå°å†™ã€å»æ‰å¤šä½™ç¬¦å·ï¼‰
    - **æ¸…ç†å™ªéŸ³**ï¼ˆURLã€æ¢è¡Œç¬¦ã€ç©ºæ ¼ï¼‰
    - **ä¿è¯ä¸€è‡´æ€§**ï¼ˆè®©åŒä¸€ä¸ªè¯åªå¯¹åº”ä¸€ç§å½¢å¼ï¼‰
    
    d. EDA:
    
    å¯è§†åŒ–ä¸€äº›åŸºæœ¬çš„ä¸œè¥¿
    
    ### **`KDE å›¾ / Boxplot / Scatterplot`**
    
    - **`KDE å›¾**ï¼šçœ‹ä¸åŒç±»åˆ«ä¸‹è¯æ•°çš„å¯†åº¦åˆ†å¸ƒï¼Œæ˜¯å¦æœ‰åç§»ã€‚`
    - **`ç®±çº¿å›¾ (Boxplot)**ï¼šæ‰¾æç«¯å€¼ï¼ˆoutliersï¼‰ã€‚`
    - **`æ•£ç‚¹å›¾ (Scatterplot)**ï¼šç›´è§‚å±•ç¤ºç±»åˆ« vs. è¯æ•°çš„å…³ç³»ã€‚`
    
    `ğŸ‘‰ æ„ä¹‰ï¼š`
    
    - `æ£€æŸ¥ç±»åˆ«é—´æ˜¯å¦æœ‰æ˜æ˜¾å·®å¼‚ã€‚`
    - `åˆ¤æ–­è¦ä¸è¦å¯¹Â **é•¿å°¾æ•°æ®**Â åšæˆªæ–­/è¿‡æ»¤ã€‚`
        - `æ¯”å¦‚ï¼šå‘ç°è´Ÿé¢è¯„è®ºå­—æ•°ç‰¹åˆ«é•¿ï¼Œå¯èƒ½è¦è€ƒè™‘åŠ Â max_featuresÂ æˆ–é•¿åº¦å½’ä¸€åŒ–ã€‚`
    
    e. åœç”¨è¯ï¼š
    
    ![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image.png)
    

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%201.png)

f. **ç‰¹å¾å·¥ç¨‹**

- **`æ•æ‰æ›´é•¿çš„ä¸Šä¸‹æ–‡**ï¼šæ¯” bigram æ›´èƒ½ä½“ç°è¯­ä¹‰ï¼Œæ¯”å¦‚ï¼š`
    - `bigram: "climate change"ï¼ˆä¸»é¢˜å¤§æ–¹å‘ï¼‰`
        - `trigram: "climate change policy"ï¼ˆæ›´å…·ä½“çš„è®®é¢˜ï¼‰`
    - **`è¯†åˆ«å…¸å‹çŸ­è¯­**ï¼šå¯ä»¥çœ‹å‡ºç”¨æˆ·è¯„è®ºé‡Œæœ€å¸¸è§çš„å®Œæ•´è¡¨è¾¾ã€‚`
    - **`ç‰¹å¾å·¥ç¨‹**ï¼šåœ¨æƒ…æ„Ÿåˆ†æã€ä¸»é¢˜å»ºæ¨¡ä¸­ï¼Œtrigram ç‰¹å¾æ¯”å•è¯æˆ– bigramèƒ½æä¾›æ›´ç»†è‡´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚`

**æ–‡æœ¬ç‰¹å¾å·¥ç¨‹ (Text Feature Engineering)ï¼š**

### `1.Â **åŸºç¡€ç‰¹å¾æå–**`

- **`word_count**ï¼ˆè¯æ•°ï¼‰ï¼šä¸€å¥è¯é‡Œå•è¯å¤šå°‘ï¼Œå¯ä»¥åæ˜ è¯„è®ºçš„é•¿åº¦å’Œä¿¡æ¯é‡ã€‚`
    - `çŸ­è¯„è®ºï¼ˆå¦‚ "ok", "bad"ï¼‰å’Œé•¿è¯„è®ºï¼ˆå¦‚ä¸€æ•´æ®µè§£é‡Šï¼‰é€šå¸¸åœ¨è¯­ä¹‰å’Œæƒ…æ„Ÿä¸Šè¡¨ç°ä¸åŒã€‚`
- **`num_chars**ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼šä¸ word_count ç±»ä¼¼ï¼Œä½†èƒ½æ›´ç»†ç²’åº¦åœ°ä½“ç°è¯„è®ºçš„å¤æ‚åº¦ã€‚`
- **`num_punctuation_chars**ï¼ˆæ ‡ç‚¹æ•°ï¼‰ï¼šæ ‡ç‚¹ï¼ˆå¦‚ "!!!", "???"ï¼‰å¸¸å¸¸å’Œæƒ…ç»ªå¼ºåº¦ç›¸å…³ï¼Œå°¤å…¶æ˜¯åœ¨ç¤¾äº¤åª’ä½“è¯„è®ºé‡Œã€‚`

---

### `2.Â **è¯­è¨€å¤æ‚åº¦ä¸é£æ ¼åˆ†æ**`

- **`num_stop_words**ï¼ˆåœç”¨è¯ä¸ªæ•°ï¼‰ï¼šåœç”¨è¯ï¼ˆå¦‚Â *the, and, is*ï¼‰é€šå¸¸ä¸æ‰¿è½½å¤ªå¤šè¯­ä¹‰ï¼Œä½†åœç”¨è¯æ¯”ä¾‹å¯ä»¥åŒºåˆ†è¯„è®ºé£æ ¼ã€‚`
    - `æ¯”å¦‚å­¦æœ¯æ€§æ–‡æœ¬ä¼šåŒ…å«æ›´å¤šåœç”¨è¯ï¼Œè€Œæƒ…ç»ªåŒ–çš„çŸ­è¯„å¯èƒ½åœç”¨è¯æ›´å°‘ã€‚`
- **`lemmatization**ï¼ˆè¯å½¢è¿˜åŸï¼‰ï¼šæŠŠÂ *running, runs â†’ run*ï¼Œå‡å°‘åŒä¹‰å½¢å¼çš„å†—ä½™ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“ç†è§£ã€‚`

---

### `3.Â **æƒ…æ„Ÿä¸åˆ†ç±»ä»»åŠ¡çš„è¾…åŠ©ç‰¹å¾**`

- `è¿™äº›ç‰¹å¾å¯ä»¥ä½œä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å…¥ï¼š`
    - **`æƒ…æ„Ÿåˆ†æ (Sentiment Analysis)**ï¼šæ ‡ç‚¹ã€åœç”¨è¯æ¯”ä¾‹ã€è¯æ•°é•¿çŸ­ï¼Œå¯èƒ½å¸®åŠ©åŒºåˆ†æ­£è´Ÿé¢è¯„è®ºã€‚`
    - **`åƒåœ¾è¯„è®ºæ£€æµ‹ (Spam Detection)**ï¼šspam è¯„è®ºå¾€å¾€æœ‰ç‰¹å®šæ¨¡å¼ï¼Œæ¯”å¦‚è¶…é•¿æ–‡æœ¬æˆ–å¤§é‡é‡å¤ç¬¦å·ã€‚`
    - **`ä¸»é¢˜å»ºæ¨¡ (Topic Modeling)**ï¼šç‰¹å¾èƒ½è¾…åŠ©æ–‡æœ¬èšç±»æˆ–åˆ†ç±»ã€‚`

---

### `4.Â **å¯è§†åŒ–ä¸æ¢ç´¢æ€§åˆ†æ**`

- `é€šè¿‡è¿™äº›ç»Ÿè®¡ï¼Œå¯ä»¥ç”»å‡ºï¼š`
    - `è¯„è®ºé•¿åº¦çš„åˆ†å¸ƒï¼›`
    - `ä¸åŒæƒ…æ„Ÿç±»åˆ«ä¸‹çš„å¹³å‡è¯æ•°å·®å¼‚ï¼›`
    - `æ ‡ç‚¹ä½¿ç”¨ä¹ æƒ¯å’Œæƒ…ç»ªçš„å…³ç³»ã€‚`
        
        `è¿™äº›ä¸ä»…èƒ½å¸®ä½ ç†è§£æ•°æ®æœ¬èº«ï¼Œè¿˜èƒ½å‘ç°æ½œåœ¨çš„å™ªéŸ³æˆ–å¼‚å¸¸ï¼ˆæ¯”å¦‚æœ‰äº›è¯„è®ºè¿‡é•¿ã€åŒ…å«æ— æ„ä¹‰å­—ç¬¦ç­‰ï¼‰ã€‚`
        
        1. **`å–æ•°ä¸åˆç­›`**
        - `è¯»å–Â reddit.csvï¼ˆ37249 è¡Œï¼Œ2 åˆ—ï¼‰ã€‚`
        - `å»ç¼ºå¤±ï¼ˆclean_commentÂ æœ‰ 100 ä¸ª NaNï¼Œå…¨ä¸ºä¸­æ€§ç±»ï¼‰ã€å»é‡å¤ã€å»ç©ºç™½è¡Œã€‚`
        1. **`æ–‡æœ¬æ¸…æ´—ï¼ˆETL-Transformï¼‰`**
        - `ç»Ÿä¸€å°å†™ã€å»é¦–å°¾ç©ºæ ¼ï¼Œæ›¿æ¢æ¢è¡Œç¬¦Â \nã€‚`
        - `æ£€æµ‹ URLï¼ˆå¯é€‰æ‹©æ€§åˆ é™¤ï¼‰ã€‚`
        - `ä»…ä¿ç•™è‹±æ–‡ä¸å¸¸è§æ ‡ç‚¹ï¼›ç»Ÿè®¡å­—ç¬¦é¢‘ç‡ã€‚`
        - `è‡ªå®šä¹‰åœç”¨è¯è¡¨ï¼ˆä¿ç•™å¦å®šè¯Â not/no/however/but/yetï¼‰ï¼Œç§»é™¤å…¶ä½™åœç”¨è¯ã€‚`
        - `è¯å½¢è¿˜åŸï¼ˆWordNetLemmatizerï¼‰ã€‚`
        1. **`ç‰¹å¾å·¥ç¨‹ï¼ˆæ•°å€¼åŒ–ç‰¹å¾ï¼‰`**
        - `word_countï¼ˆè¯æ•°ï¼‰ã€num_charsï¼ˆå­—ç¬¦æ•°ï¼‰ã€num_stop_wordsï¼ˆåœç”¨è¯æ•°ï¼‰ã€num_punctuation_charsï¼ˆæ ‡ç‚¹æ•°ï¼‰ã€‚`
        - `ç›®çš„ï¼šæŠŠâ€œæ–‡æœ¬é£æ ¼/é•¿åº¦/æƒ…ç»ªå¼ºåº¦â€è½¬æ¢ä¸ºå¯ç”¨äºå»ºæ¨¡çš„æ•°å€¼ç‰¹å¾ã€‚`
        1. **`EDAï¼ˆæ¢ç´¢æ€§åˆ†æä¸å¯è§†åŒ–ï¼‰`**
        - `ç±»åˆ«å æ¯”ï¼šæ­£é¢ 42.86%ã€ä¸­æ€§ 34.71%ã€è´Ÿé¢ 22.42%ã€‚`
        - `è¯æ•°åˆ†å¸ƒï¼ˆKDE/ç®±çº¿å›¾/ä¸­ä½æ•°æŸ±çŠ¶å›¾ï¼‰ï¼šæ­£é¢ä¸è´Ÿé¢æ›´â€œå•°å—¦â€ï¼Œä¸­æ€§æ›´çŸ­ã€‚`
        - `åœç”¨è¯æ•°é‡åˆ†å¸ƒä¸ Top-25 åœç”¨è¯ã€‚`
        - `N-gramï¼šTop-25Â **bigrams**Â ä¸Â **trigrams**ï¼ˆå¸¸è§çŸ­è¯­ï¼Œæ•æ‰ä¸Šä¸‹æ–‡æ­é…ï¼‰ã€‚`
        - `è¯äº‘ï¼šæ•´ä½“ã€ä»¥åŠæŒ‰æƒ…æ„Ÿç±»åˆ«åˆ†åˆ«ç»˜åˆ¶ã€‚`
        - `Top-N è¯é¢‘ï¼ˆæ•´ä½“ & æŒ‰æƒ…æ„Ÿå †å æŸ±çŠ¶å›¾ï¼‰ï¼šå±•ç¤ºåŒä¸€è¯åœ¨ä¸‰ç±»æƒ…æ„Ÿä¸­çš„å‡ºç°ç»“æ„ã€‚`
        1. **`ç”¨é€”ä¸ä»·å€¼`**
        - `æ¸…æ´—ä¸ç‰¹å¾è®©æ–‡æœ¬æ›´â€œå¹²å‡€ä¸€è‡´â€ï¼Œä¾¿äºåç»­Â **å‘é‡åŒ–/å»ºæ¨¡**ï¼›`
        - `EDA æ­ç¤ºå·®å¼‚ï¼ˆå¦‚é•¿åº¦ã€åœç”¨è¯æ¯”ä¾‹ã€å…¸å‹çŸ­è¯­ï¼‰ï¼ŒæŒ‡å¯¼Â **ç‰¹å¾é€‰æ‹©**Â ä¸Â **æ¨¡å‹å‡è®¾**ï¼ˆä¾‹å¦‚æŠŠé•¿åº¦ç±»ç‰¹å¾ä¸ TF-IDF/è¯å‘é‡ä¸€èµ·å–‚ç»™æ¨¡å‹ï¼‰ã€‚`

4. **Setup MLflow server on AWS**

â†’ åœ¨ AWS ä¸Šæ­å»ºÂ **MLflow æœåŠ¡å™¨**ï¼šç”¨äºç®¡ç†æœºå™¨å­¦ä¹ å®éªŒï¼ŒåŒ…æ‹¬æ¨¡å‹è®­ç»ƒæ—¥å¿—ã€å‚æ•°ã€æŒ‡æ ‡ã€æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ç­‰ã€‚

1. **IAM ç”¨æˆ·**
- **ml_server**
    - è¿™æ˜¯ä½ åˆ›å»ºçš„ IAM ç”¨æˆ·ï¼Œç»™å®ƒåˆ†é…äº†è®¿é—® S3 çš„æƒé™ã€‚
    - å®ƒæœ‰ä¸€ç»„Â **Access Key ID**Â å’ŒÂ **Secret Access Key**ï¼Œéœ€è¦åœ¨ EC2 ä¸Šé…ç½®ï¼Œä¾› MLflow ä½¿ç”¨ã€‚

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%202.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%203.png)

1. **S3 å­˜å‚¨æ¡¶**
- **mlbucket922**
    - è¿™æ˜¯ä½ åœ¨ S3 ä¸Šåˆ›å»ºçš„ bucketï¼ˆå­˜å‚¨æ¡¶ï¼‰ï¼Œç”¨æ¥å­˜æ”¾ MLflow çš„ artifactï¼ˆæ¨¡å‹ã€æ—¥å¿—ã€æ–‡ä»¶ç­‰ï¼‰ã€‚

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%204.png)

1. **EC2 å®ä¾‹**
- **i-0b7f2bf64c9769970 (ml-machine)**
    - è¿™æ˜¯ä½ åˆ›å»ºçš„Â **EC2 è™šæ‹Ÿæœºå®ä¾‹**ï¼Œç›¸å½“äºä¸€å°äº‘æœåŠ¡å™¨ã€‚
- **ml_server**
    - è¿™æ˜¯ä½ åˆ›å»ºçš„ IAM ç”¨æˆ·ï¼Œç»™å®ƒåˆ†é…äº†è®¿é—® S3 çš„æƒé™ã€‚
    - å®ƒæœ‰ä¸€ç»„Â **Access Key ID**Â å’ŒÂ **Secret Access Key**ï¼Œéœ€è¦åœ¨ EC2 ä¸Šé…ç½®ï¼Œä¾› MLflow ä½¿ç”¨ã€‚

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%205.png)

1. open ec2
    
       
    
    1. `æ›´æ–°åŒ…åˆ—è¡¨`
    
    ```bash
    sudo apt update
    
    ```
    
    1. `å®‰è£… pipï¼ˆPython 3 çš„åŒ…ç®¡ç†å™¨ï¼‰`
    
    ```bash
    sudo apt install python3-pip
    
    ```
    
    1. `å®‰è£… pipenv`
    
    ```bash
    sudo apt install pipenv
    
    ```
    
    1. `å®‰è£… virtualenv`
    
    ```bash
    sudo apt install virtualenv
    
    ```
    
    1. `åˆ›å»ºå¹¶è¿›å…¥é¡¹ç›®ç›®å½•`
    
    ```bash
    mkdir mlflow
    cd mlflow
    
    ```
    
    1. `ç”¨ pipenv å®‰è£…éœ€è¦çš„åŒ…`
    
    ```bash
    pipenv install mlflow
    pipenv install awscli
    pipenv install boto3
    
    ```
    
    1. `è¿›å…¥ pipenv ç¯å¢ƒ`
    
    ```bash
    pipenv shell
    
    aws configure
    
    ```
    
2. 

### .Â **MLflow å¯åŠ¨å‘½ä»¤**

åœ¨ EC2 é‡Œè¿è¡Œï¼š

```bash
mlflow server \
    --host 0.0.0.0 \
    --default-artifact-root s3://mlbucket922 \
mlflow server \
    --host 0.0.0.0 \
    --default-artifact-root s3://mlbucket922 \
```

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%206.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%207.png)

[https://www.notion.so](https://www.notion.so)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%208.png)

[ec2-34-238-171-48.compute-1.amazonaws.com](http://ec2-34-238-171-48.compute-1.amazonaws.com/)

http://ec2-34-238-171-48.compute-1.amazonaws.com/

[http://ec2-34-238-171-48.compute-1.amazonaws.com:5000/](http://ec2-34-238-171-48.compute-1.amazonaws.com:5000/)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%209.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2010.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2011.png)

1. **å®‰è£…å¹¶è¿ä¸Š MLflow Server**
- å®‰è£…Â `mlflow`ï¼Œå¹¶æŠŠè¿½è¸ªåœ°å€æŒ‡å‘ä½ çš„ EC2ï¼š
    
    `mlflow.set_tracking_uri("http://ec2-54-175-41-29.compute-1.amazonaws.com:5000/")`
    
- è¿è¡Œä»»ä½•Â `mlflow.start_run()`Â å†…çš„ä»£ç ï¼Œå‚æ•°ã€æŒ‡æ ‡ã€å·¥ä»¶éƒ½ä¼šè¢«å‘åˆ°é‚£ä¸ªæœåŠ¡ç«¯ã€‚
- ä½ åˆ›å»ºäº†å®éªŒÂ **â€œRF Baselineâ€**ï¼ˆè‹¥ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»ºï¼‰ã€‚æ§åˆ¶å°æç¤ºé‡Œçš„é“¾æ¥èƒ½ç›´æ¥æ‰“å¼€åˆ° Run/Experiment é¡µé¢ã€‚
1. **S3 åšå·¥ä»¶ï¼ˆartifactsï¼‰å­˜å‚¨**
- ä»æ—¥å¿—ï¼š`artifact_location='s3://mlflow-test-25/...'`Â å¯è§ï¼Œæ¨¡å‹æ–‡ä»¶ã€å›¾åƒã€æ•°æ®ç­‰å·¥ä»¶éƒ½å­˜è¿›äº† S3ï¼ˆä½ çš„ bucketï¼‰ã€‚
- ä½ æŠŠÂ `confusion_matrix.png`Â å’ŒÂ `dataset.csv`Â éƒ½ä½œä¸ºå·¥ä»¶ä¸Šä¼ äº†ï¼›æ¨¡å‹ä¿å­˜åœ¨Â `random_forest_model/`Â ç›®å½•ä¸‹ã€‚
1. **æ•°æ®é¢„å¤„ç†ï¼ˆç›¸å½“äºå°å‹ ETLï¼‰**
- è¯»å…¥ reddit æ•°æ® â†’Â `dropna`Â / å»é‡ / å»ç©ºç™½æ ·æœ¬ã€‚
- ç»Ÿä¸€å°å†™ã€å»é¦–å°¾ç©ºæ ¼ã€æ¸…ç†æ¢è¡Œã€ä¿ç•™å¸¸è§æ ‡ç‚¹ã€å»æ‰éè‹±æ–‡å­—å…ƒã€‚
- **åœç”¨è¯**ï¼šä¿ç•™äº†â€œnot, no, but, however, yetâ€ç­‰å¦å®š/è½¬æŠ˜è¯ï¼ˆå¯¹æƒ…æ„Ÿå¾ˆå…³é”®ï¼‰ã€‚
- **Lemmatization**ï¼šç”¨Â `WordNetLemmatizer`Â åšè¯å½¢è¿˜åŸã€‚
    
    â†’ è¾“å‡ºåˆ—ä»å«Â `clean_comment`ï¼ˆå¹²å‡€æ–‡æœ¬ï¼‰ï¼Œè¿™ä¸€æ­¥å°±æ˜¯â€œä¸ºå»ºæ¨¡åšå¹²å‡€è¾“å…¥â€ã€‚
    
1. **ç‰¹å¾åŒ– + æ¨¡å‹**
- ç”¨Â **Bag of Wordsï¼ˆCountVectorizerï¼‰**ï¼Œ`max_features=10000`Â â†’ å˜æˆ 36,793 Ã— 10,000 çš„ç¨€ç–ç‰¹å¾çŸ©é˜µã€‚
- åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•ï¼Œè®­ç»ƒÂ **RandomForestClassifier**ï¼ˆ`n_estimators=200, max_depth=15`ï¼‰ã€‚
- è®°å½•Â **accuracy**ã€**classification_report**Â çš„å„ç±»æŒ‡æ ‡ï¼Œå¹¶äº§å‡ºæ··æ·†çŸ©é˜µå›¾ã€‚
1. **MLflow è®°å½•äº†ä»€ä¹ˆ**
- **Params**ï¼šçŸ¢é‡åŒ–æ–¹å¼ã€max_featuresã€RF çš„ n_estimatorsã€max_depth ç­‰ã€‚
- **Metrics**ï¼šaccuracyã€ä»¥åŠæ¯ä¸ªç±»åˆ«ï¼ˆ-1/0/1ï¼‰çš„ precision/recall/f1ã€‚
- **Artifacts**ï¼š`confusion_matrix.png`ã€`dataset.csv`ã€ä»¥åŠÂ **å·²ä¿å­˜çš„æ¨¡å‹**ï¼ˆ`random_forest_model`ï¼‰ã€‚

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2012.png)

è¿™æ˜¯åœ¨æŠŠÂ **MLflow å®¢æˆ·ç«¯**è¿åˆ°ä½ çš„æœåŠ¡ç«¯ï¼Œå¹¶åˆ›å»º/åˆ‡æ¢åˆ°ä¸€ä¸ªå®éªŒã€‚

å…·ä½“å«ä¹‰ï¼š

1. `mlflow.set_tracking_uri("http://ec2-34-238-171-48.compute-1.amazonaws.com:5000/")`
    - å‘Šè¯‰æœ¬åœ°/ç¬”è®°æœ¬é‡Œçš„ MLflow å®¢æˆ·ç«¯ï¼šä»¥åæ‰€æœ‰Â **runs çš„å‚æ•°ã€æŒ‡æ ‡ã€å·¥ä»¶ä¿¡æ¯**Â éƒ½å‘åˆ°è¿™ä¸ªÂ **MLflow Tracking Server**ï¼ˆä½ åœ¨ EC2 ä¸Šå¼€çš„ 5000 ç«¯å£ï¼‰ã€‚
2. `mlflow.set_experiment("RF Baseline")`
    - é€‰æ‹©åä¸º â€œRF Baselineâ€ çš„Â **Experiment**Â ä½œä¸ºå½“å‰å®éªŒç©ºé—´ï¼›
    - æ—¥å¿—é‡Œæç¤º â€œdoes not exist. Creating a new experiment.â€ è¡¨ç¤ºè¯¥å®éªŒä¸å­˜åœ¨ï¼Œäºæ˜¯**åœ¨æœåŠ¡ç«¯æ–°å»º**äº†ä¸€ä¸ªï¼Œå¹¶è¿”å›ï¼š
        - `experiment_id`ï¼šå®éªŒçš„å”¯ä¸€ IDï¼ˆåé¢æ‰€æœ‰ runs éƒ½å½’åˆ°è¿™ä¸ªå®éªŒåä¸‹ï¼‰ã€‚
        - `artifact_location='s3://mlbucket922/â€¦'`ï¼šè¯¥å®éªŒçš„**å·¥ä»¶æ ¹ç›®å½•**ï¼ˆæ¨¡å‹ã€å›¾åƒã€csv ç­‰ä¼šå­˜åˆ°è¿™ä¸ª S3 è·¯å¾„ä¸‹ï¼‰ã€‚

ä»¥åä½ åœ¨Â `with mlflow.start_run(): ...`Â ä¸­çš„Â `log_param / log_metric / log_artifact / log_model`ï¼š

- **å…ƒæ•°æ®**ï¼ˆå‚æ•°ã€æŒ‡æ ‡ã€tagsã€runs ç»“æ„ï¼‰ä¿å­˜åœ¨ MLflow æœåŠ¡å™¨çš„åç«¯å­˜å‚¨ï¼›
- **å·¥ä»¶**ï¼ˆæ¨¡å‹æ–‡ä»¶ã€å›¾ç‰‡ã€æ•°æ®ï¼‰æŒ‰ä¸Šé¢çš„Â `artifact_location`Â å­˜è¿›Â **S3**Â å¯¹åº”å‰ç¼€ã€‚
    
    è¿™æ ·ä½ å°±èƒ½åœ¨ MLflow UIï¼ˆ5000 ç«¯å£ï¼‰é‡Œçœ‹åˆ°è¯¥å®éªŒä¸‹æ‰€æœ‰ run çš„è®°å½•ä¸å·¥ä»¶é“¾æ¥ã€‚
    

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2013.png)

ï¼šä½ è¿™æ¬¡æ˜¯åœ¨**åšç‰¹å¾å·¥ç¨‹å¯¹æ¯”å®éªŒ**ï¼ŒæŠŠâ€œåªç”¨ BoWï¼ˆCountVectorizerï¼‰â€å‡çº§ä¸º**BoW vs TF-IDF**Â +Â **ä¸åŒ n-gram**Â ç»„åˆçš„ç³»ç»Ÿæ¯”è¾ƒï¼Œå¹¶æŠŠæ¯æ¬¡ç»“æœéƒ½è®°åˆ°åŒä¸€ä¸ª MLflow å®éªŒé‡Œã€‚

## å’Œâ€œåˆšåˆšâ€çš„åŒºåˆ«

| ç‚¹ | ä¹‹å‰ï¼ˆRF Baselineï¼‰ | ç°åœ¨ï¼ˆExp 2 - BoW vs TfIdfï¼‰ |
| --- | --- | --- |
| å‘é‡åŒ– | **CountVectorizer**ï¼ˆBoWï¼‰ä¸€ç§ï¼Œ`max_features=10000`ï¼Œé»˜è®¤Â `ngram_range=(1,1)` | **å¯åˆ‡æ¢**ï¼šBoWÂ **æˆ–**Â TF-IDFï¼›å¹¶å¾ªç¯Â **(1,1)ã€(1,2)ã€(1,3)**ï¼›`max_features=5000` |
| å®éªŒç»“æ„ | å•æ¬¡ run | ä¸€æ¬¡è„šæœ¬è§¦å‘Â **6 ä¸ª run**ï¼ˆBoWÃ—3 + TF-IDFÃ—3ï¼‰ï¼Œä¾¿äºæ¨ªå‘å¯¹æ¯” |
| è®°å½• | å‚æ•°/æŒ‡æ ‡/æ··æ·†çŸ©é˜µ/æ¨¡å‹ | åŒä¸Šï¼Œä½†æ¯ä¸ª run ä¼šå¸¦ä¸Šå‘é‡å™¨åã€n-gram ä½œä¸º tag/paramï¼ŒUI å¯¹æ¯”æ›´æ¸…æ™° |
| ç›®æ ‡ | è·‘é€šåŸºçº¿ | æ¯”è¾ƒ**å“ªç§å‘é‡åŒ–æ›´å¥½**ï¼ˆä»¥åŠå“ªç§ n-gram è®¾ç½®æ›´åˆé€‚ï¼‰ |

## â€œWhich vectorization?â€â€”â€”ä¸¤ç§å‘é‡åŒ–çš„æœ¬è´¨

- **BoWï¼ˆCountVectorizerï¼‰**
    
    ç»Ÿè®¡è¯æˆ– n-gram çš„**å‡ºç°æ¬¡æ•°**ã€‚
    
    ä¼˜ç‚¹ï¼šç®€å•ã€ç¨³å®šã€é€Ÿåº¦å¿«ã€‚
    
    ç¼ºç‚¹ï¼šé«˜é¢‘åœç”¨è¯æƒé‡å¯èƒ½è¿‡å¤§ï¼ˆä½ å‰é¢å·²åšåœç”¨è¯å¤„ç†ï¼Œå½±å“å‡å¼±ï¼‰ã€‚
    
- **TF-IDFï¼ˆTfidfVectorizerï¼‰**
    
    åœ¨è¯é¢‘åŸºç¡€ä¸Šä¹˜ä»¥Â **IDF**ï¼Œ**é™ä½å…¨å±€å¸¸è§è¯**ã€**æé«˜åŒºåˆ†åº¦é«˜çš„è¯**çš„æƒé‡ã€‚
    
    å¸¸åœ¨æ–‡æœ¬åˆ†ç±»/ä¿¡æ¯æ£€ç´¢é‡Œè¡¨ç°æ›´å¥½ï¼Œå°¤å…¶æ˜¯â€œè¯å¾ˆå¸¸è§ä½†æ²¡å•¥åŒºåˆ†åº¦â€çš„åœºæ™¯ã€‚
    
- **n-gram**
    - (1,1)ï¼šä»…å•è¯ï¼›
    - (1,2)ï¼šå•è¯+äºŒå…ƒç»„ï¼ˆèƒ½å¼•å…¥çŸ­è¯­æ¨¡å¼ï¼Œå¦‚ â€œnot goodâ€ï¼‰ï¼›
    - (1,3)ï¼šå†åŠ ä¸‰å…ƒç»„ï¼Œè¡¨è¾¾åŠ›æ›´å¼ºä½†æ›´ç¨€ç–ã€ç»´åº¦æ›´é«˜ã€‚

## ç»“è®ºæ€ä¹ˆé€‰ï¼Ÿ

- æ‰“å¼€ MLflow UI â†’ å®éªŒÂ **â€œExp 2 - BoW vs TfIdfâ€**ï¼Œæ¯”è¾ƒå„ run çš„**æŒ‡æ ‡**ã€‚
    
    æ•°æ®**ç±»åˆ«ä¸å¹³è¡¡**ï¼ˆä½ å‰é¢æŠ¥å‘Šé‡Œ -1 å¬å›å¾ˆä½ï¼‰ï¼Œä»…çœ‹ accuracy ä¼šè¢«â€œå¤šæ•°ç±»â€æ©ç›–ã€‚
    
    - å»ºè®®ä¼˜å…ˆçœ‹Â **macro F1**ã€**1 ç±»çš„ recall/F1**ã€‚
- ç»éªŒä¸Šï¼š**TF-IDF + (1,2)**Â å¾€å¾€åœ¨æ–‡æœ¬åˆ†ç±»æ›´ç¨³ï¼›ä½†è¦ä»¥ä½ è¿™æ¬¡çš„æŒ‡æ ‡ä¸ºå‡†ã€‚
- å¦‚æœ TF-IDF çš„å®å¹³å‡ F1 æ›´å¥½ï¼ˆç‰¹åˆ«æ˜¯ -1 ç±»æå‡ï¼‰ï¼Œå°±é€‰å®ƒä½œä¸ºåç»­é»˜è®¤å‘é‡åŒ–ã€‚

### ğŸ”¹ ç¬¬ä¸€ä¸ªå®éªŒï¼ˆBaseline RFï¼‰

- **æ•°æ®æ¥æº**ï¼šç›´æ¥è¯»åŸå§‹çš„Â `reddit.csv`ï¼Œç„¶ååšäº†æ¸…æ´—ï¼ˆå»æ‰ NaNã€å»æ‰ç©ºå­—ç¬¦ä¸²ã€å»æ‰é‡å¤ã€æ­£åˆ™æ¸…ç†ã€åœç”¨è¯å¤„ç†ã€è¯å½¢è¿˜åŸï¼‰ã€‚
- **ä¿å­˜**ï¼šæœ€åç”¨
    
    ```python
    df.to_csv('reddit_preprocessing.csv', index=False)
    
    ```
    
    å¾—åˆ°Â `36793`Â è¡Œã€‚
    
- **è®­ç»ƒæ•°æ®å¤§å°**ï¼šçº¦Â **36,793**Â è¡Œã€‚

---

### ğŸ”¹ ç¬¬äºŒä¸ªå®éªŒï¼ˆBoW vs TF-IDFï¼‰

- **æ•°æ®æ¥æº**ï¼šä¸æ˜¯é‡æ–°æ¸…æ´—åŸå§‹Â `reddit.csv`ï¼Œè€Œæ˜¯ç›´æ¥è¯»Â **`reddit_preprocessing.csv`**ã€‚
    
    è¿™æ—¶å› ä¸ºé¢å¤–Â `dropna`Â +Â `drop_duplicates`ï¼Œä»¥åŠå­˜å‚¨è¿‡ç¨‹ä¸­æ ¼å¼å·®å¼‚ï¼Œç»“æœå°‘äº†ä¸€éƒ¨åˆ†è¡Œã€‚
    
- **ä½ æˆªå›¾æ˜¾ç¤º**ï¼š`df.shape = (36662, 2)`ï¼Œæ¯”ç¬¬ä¸€æ¬¡å°‘äº†å¤§æ¦‚Â `131`Â è¡Œã€‚
- **è®­ç»ƒæ•°æ®å¤§å°**ï¼šçº¦Â **36,662**Â è¡Œã€‚

---

### âš ï¸ é—®é¢˜

æ‰€ä»¥è¿™ä¸¤ä¸ªå®éªŒè®­ç»ƒçš„æ¨¡å‹ï¼Œè™½ç„¶é€»è¾‘ç±»ä¼¼ï¼Œä½†Â **æ•°æ®é›†æ ·æœ¬æ•°ä¸åŒ**ï¼Œä¸¥æ ¼å¯¹æ¯”å¹¶ä¸å…¬å¹³ã€‚

---

### âœ… å»ºè®®åšæ³•ï¼ˆä¿è¯å¯æ¯”æ€§ï¼‰

å¦‚æœä½ æƒ³è¦ä¸€ä¸ªã€Œå¹²å‡€çš„å¯¹æ¯”ï¼šBoW vs TF-IDFã€ï¼š

1. **ç»Ÿä¸€æ•°æ®æº**ï¼šå§‹ç»ˆä»æœ€åŸå§‹çš„Â `reddit.csv`Â å¼€å§‹æ¸…æ´—ï¼Œç„¶åä¿å­˜ä¸€ä»½æœ€ç»ˆç¨³å®šçš„æ•°æ®é›†ï¼Œä¾‹å¦‚ï¼š
    
    ```python
    df_clean = clean_pipeline(raw_df)   # ç»Ÿä¸€çš„é¢„å¤„ç†å‡½æ•°
    df_clean.to_csv("reddit_final.csv", index=False)
    
    ```
    
2. **å›ºå®šéšæœºç§å­**ï¼šåœ¨Â `train_test_split`Â é‡Œå·²ç»åŠ äº†Â `random_state=42`ï¼Œè¿™éƒ¨åˆ†æ˜¯å›ºå®šçš„ï¼Œå¯ä»¥ä¿è¯åˆ‡åˆ†ä¸€è‡´ã€‚
3. **åç»­å®éªŒ**ï¼šä¸ç®¡æ˜¯ Baseline RF è¿˜æ˜¯ BoW vs TF-IDFï¼Œå…¨éƒ¨ä½¿ç”¨Â **åŒä¸€ä»½Â `reddit_final.csv`**ï¼Œè¿™æ ·å¯¹æ¯”ç»“æœæ‰æœ‰æ„ä¹‰ã€‚

```python

# Step 1: Function to run the experiment
def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):
    # Step 2: Vectorization
    if vectorizer_type == "BoW":
        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)
    else:
        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)

    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])

    X_train = vectorizer.fit_transform(X_train)
    X_test = vectorizer.transform(X_test)

    # Step 4: Define and train a Random Forest model
    with mlflow.start_run() as run:
        # Set tags for the experiment and run
        mlflow.set_tag("mlflow.runName", f"{vectorizer_name}_{ngram_range}_RandomForest")
        mlflow.set_tag("experiment_type", "feature_engineering")
        mlflow.set_tag("model_type", "RandomForestClassifier")

        # Add a description
        mlflow.set_tag("description", f"RandomForest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}")

        # Log vectorizer parameters
        mlflow.log_param("vectorizer_type", vectorizer_type)
        mlflow.log_param("ngram_range", ngram_range)
        mlflow.log_param("vectorizer_max_features", vectorizer_max_features)

        # Log Random Forest parameters
        n_estimators = 200
        max_depth = 15

        mlflow.log_param("n_estimators", n_estimators)
        mlflow.log_param("max_depth", max_depth)

        # Initialize and train the model
        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
        model.fit(X_train, y_train)

        # Step 5: Make predictions and log metrics
        y_pred = model.predict(X_test)

        # Log accuracy
        accuracy = accuracy_score(y_test, y_pred)
        mlflow.log_metric("accuracy", accuracy)

        # Log classification report
        classification_rep = classification_report(y_test, y_pred, output_dict=True)
        for label, metrics in classification_rep.items():
            if isinstance(metrics, dict):
                for metric, value in metrics.items():
                    mlflow.log_metric(f"{label}_{metric}", value)

        # Log confusion matrix
        conf_matrix = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        plt.title(f"Confusion Matrix: {vectorizer_name}, {ngram_range}")
        plt.savefig("confusion_matrix.png")
        mlflow.log_artifact("confusion_matrix.png")
        plt.close()

        # Log the model
        mlflow.sklearn.log_model(model, f"random_forest_model_{vectorizer_name}_{ngram_range}")

# Step 6: Run experiments for BoW and TF-IDF with different n-grams
ngram_ranges = [(1, 1), (1, 2), (1, 3)]  # unigrams, bigrams, trigrams
max_features = 5000  # Example max feature size

for ngram_range in ngram_ranges:
    # BoW Experiments
    run_experiment("BoW", ngram_range, max_features, vectorizer_name="BoW")

    # TF-IDF Experiments
    run_experiment("TF-IDF", ngram_range, max_features, vectorizer_name="TF-IDF")

```

## 1) æ ¸å¿ƒç›®æ ‡

å¯¹åŒä¸€ä»½æ–‡æœ¬æ•°æ®ï¼Œæ¯”è¾ƒä¸¤ç§**å‘é‡åŒ–æ–¹å¼**ä¸ä¸åŒÂ **n-gram**Â è®¾ç½®åœ¨åŒä¸€æ¨¡å‹ï¼ˆRandomForestï¼‰ä¸‹çš„æ•ˆæœï¼Œå¹¶æŠŠæ¯æ¬¡è¯•éªŒè®°å½•åˆ°Â **MLflow**ï¼ˆå‚æ•°ã€æŒ‡æ ‡ã€æ··æ·†çŸ©é˜µå›¾ã€æ¨¡å‹æ–‡ä»¶ï¼‰ã€‚

æ¯”è¾ƒçš„é…ç½®ï¼š

- å‘é‡åŒ–ï¼š**BoW**ï¼ˆ`CountVectorizer`ï¼‰ vsÂ **TF-IDF**ï¼ˆ`TfidfVectorizer`ï¼‰
- n-gramï¼š`(1,1)`Â (unigram),Â `(1,2)`Â (uni+bi),Â `(1,3)`Â (uni+bi+tri)
- ç‰¹å¾æ•°ä¸Šé™ï¼š`max_features=5000`
- æ¨¡å‹ï¼š`RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42)`

## 2) å‡½æ•°Â `run_experiment(...)`Â è¯¦è§£

```python
def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):

```

### (a) æ–‡æœ¬å‘é‡åŒ–é…ç½®

```python
if vectorizer_type == "BoW":
    vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)
else:
    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)

```

- `ngram_range`Â æ§åˆ¶ n-gram ç‰‡æ®µèŒƒå›´ï¼›è¶Šå¤§èƒ½æ•æ‰æ›´å¤šå±€éƒ¨çŸ­è¯­ï¼Œä½†ç¨€ç–åº¦å˜é«˜ã€‚
- `max_features`Â æ§åˆ¶ä¿ç•™çš„é«˜é¢‘ç‰¹å¾ä¸Šé™ï¼›è¶Šå¤§ä¿¡æ¯è¶Šå¤šï¼Œå†…å­˜å’Œæ—¶é—´ä¹Ÿè¶Šå¤§ã€‚

### (b) æ•°æ®åˆ‡åˆ†ï¼ˆé¿å…ä¿¡æ¯æ³„æ¼ï¼‰

```python
X_train, X_test, y_train, y_test = train_test_split(
    df['clean_comment'], df['category'],
    test_size=0.2, random_state=42, stratify=df['category']
)
X_train = vectorizer.fit_transform(X_train)   # åªåœ¨è®­ç»ƒé›† fit
X_test = vectorizer.transform(X_test)         # æµ‹è¯•é›†ä»… transform

```

- `stratify`Â ä¿è¯ç±»åˆ«åˆ†å¸ƒåœ¨ train/test ä¸€è‡´ã€‚
- åªåœ¨Â **è®­ç»ƒé›†**Â ä¸ŠÂ `fit`Â å‘é‡å™¨ï¼Œé¿å…æ•°æ®æ³„æ¼ï¼ˆåšå¾—å¯¹ âœ…ï¼‰ã€‚

### (c) å¯åŠ¨ä¸€æ¬¡ MLflow è¿è¡Œå¹¶è®°å½•å…ƒæ•°æ®

```python
with mlflow.start_run() as run:
    mlflow.set_tag("mlflow.runName", f"{vectorizer_name}_{ngram_range}_RandomForest")
    mlflow.set_tag("experiment_type", "feature_engineering")
    mlflow.set_tag("model_type", "RandomForestClassifier")

```

- `runName`Â ä¼šç›´æ¥æ˜¾ç¤ºåœ¨ MLflow UIï¼Œä¾¿äºåŒºåˆ†æ¯ä¸ªé…ç½®ã€‚

### (d) è®°å½•å‚æ•°ï¼ˆparamsï¼‰

```python
mlflow.log_param("vectorizer_type", vectorizer_type)
mlflow.log_param("ngram_range", ngram_range)
mlflow.log_param("vectorizer_max_features", vectorizer_max_features)
mlflow.log_param("n_estimators", 200)
mlflow.log_param("max_depth", 15)

```

### (e) è®­ç»ƒ + é¢„æµ‹

```python
model = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

```

### (f) è®°å½•æŒ‡æ ‡ï¼ˆmetricsï¼‰

```python
accuracy = accuracy_score(y_test, y_pred)
mlflow.log_metric("accuracy", accuracy)

classification_rep = classification_report(y_test, y_pred, output_dict=True)
for label, metrics in classification_rep.items():
    if isinstance(metrics, dict):
        for metric, value in metrics.items():
            mlflow.log_metric(f"{label}_{metric}", value)

```

- é™¤äº†æ€»ä½“Â `accuracy`ï¼Œè¿˜æŠŠæ¯ä¸ªç±»åˆ«çš„Â `precision/recall/f1-score/support`Â éƒ½æ‰“ç‚¹åˆ° MLflowï¼ˆå¦‚Â `1_precision`,Â `1_f1-score`Â ç­‰ï¼‰ã€‚

### (g) è®°å½•æ··æ·†çŸ©é˜µå›¾ï¼ˆartifactï¼‰

```python
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.title(f"Confusion Matrix: {vectorizer_name}, {ngram_range}")
plt.savefig("confusion_matrix.png")
mlflow.log_artifact("confusion_matrix.png")
plt.close()

```

- ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶å¹¶ä½œä¸ºÂ **artifact**Â ä¸Šä¼ åˆ° MLflowï¼ˆå¦‚æœ MLflow è®¾ç½®äº† S3 artifact storeï¼Œè¿™å¼ å›¾ä¹Ÿä¼šè¿›ä½ çš„ S3 æ¡¶é‡Œï¼‰ã€‚

### (h) è®°å½•æ¨¡å‹ï¼ˆartifactï¼‰

```python
mlflow.sklearn.log_model(model, f"random_forest_model_{vectorizer_name}_{ngram_range}")

```

- åœ¨ MLflow UI çš„æ¯ä¸ª run é‡Œå¯ä»¥ç‚¹å‡»ä¸‹è½½æ¨¡å‹ï¼›ä¹Ÿå¯ä»¥ç”¨Â `mlflow.sklearn.load_model()`Â å›è½½ã€‚

---

## 3) æ‰¹é‡è¯•éªŒå…¥å£

```python
ngram_ranges = [(1, 1), (1, 2), (1, 3)]
max_features = 5000

for ngram_range in ngram_ranges:
    run_experiment("BoW", ngram_range, max_features, vectorizer_name="BoW")
    run_experiment("TF-IDF", ngram_range, max_features, vectorizer_name="TF-IDF")

```

- ä¸€å…±ä¼šäº§ç”ŸÂ **6 ä¸ª run**ï¼šBoW Ã—3 + TF-IDF Ã—3ã€‚
- æ¯ä¸ª run éƒ½ä¼šåœ¨ MLflow é‡Œæœ‰ç‹¬ç«‹çš„å‚æ•°ã€æŒ‡æ ‡ã€å›¾å’Œæ¨¡å‹æ–‡ä»¶ï¼Œæ–¹ä¾¿æ¨ªå‘å¯¹æ¯”ã€‚

## 2ï¸âƒ£ ä¸åŒå‘é‡åŒ–æ–¹æ³• â†’ ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ä¸åŒ

### BoW (Bag of Words)

- åªç»Ÿè®¡è¯é¢‘ï¼ˆæŸä¸ªè¯å‡ºç°å‡ æ¬¡ï¼‰ã€‚
- ç®€å•ç›´è§‚ï¼Œä½†Â **å¿½ç•¥è¯è¯­é¡ºåº**ï¼ŒåŒºåˆ†èƒ½åŠ›æœ‰é™ã€‚
- å¸¸å¸¸æŠŠé«˜é¢‘è¯å½“æˆé‡è¦è¯ï¼Œä½†åœ¨æƒ…æ„Ÿåˆ†æé‡Œï¼ŒåƒÂ *not*Â è¿™ç§ä½é¢‘è¯å¯èƒ½æ›´å…³é”®ã€‚

### TF-IDF (Term Frequency â€“ Inverse Document Frequency)

- åœ¨ BoW åŸºç¡€ä¸ŠåŠ äº†ã€Œé€†æ–‡æ¡£é¢‘ç‡ã€ï¼Œé™ä½å…¨å±€é«˜é¢‘è¯ï¼ˆå¦‚Â *the*,Â *and*ï¼‰ï¼Œæå‡é‚£äº›åœ¨å°‘æ•°æ–‡æ¡£é‡Œæ‰å‡ºç°çš„è¯ï¼ˆå¦‚Â *excellent*,Â *horrible*ï¼‰ã€‚
- æ›´é€‚åˆæ•æ‰æƒ…æ„Ÿ/ä¸»é¢˜ï¼Œå¾€å¾€æ¯”å•çº¯ BoW è¡¨ç°æ›´å¥½ã€‚

### N-grams (n=2,3 â€¦)

- å…è®¸æ¨¡å‹è€ƒè™‘çŸ­è¯­è€Œä¸æ˜¯å•ä¸ªè¯ã€‚
- ä¾‹å¦‚Â *â€œnot goodâ€*ï¼š
    - åœ¨ BoW/TF-IDF unigram ä¸‹ï¼š`not`Â å’ŒÂ `good`Â åˆ†å¼€ï¼Œæ¨¡å‹å¯èƒ½å­¦ä¸åˆ°â€œå¦å®šæƒ…æ„Ÿâ€ã€‚
    - åœ¨ bigram ä¸‹ï¼š`not good`Â ä¼šå˜æˆä¸€ä¸ªç‰¹å¾ â†’ æ›´å¼ºåŒºåˆ†åŠ›ã€‚

---

## 3ï¸âƒ£ ä¸åŒä»»åŠ¡å¯¹å‘é‡åŒ–æ•æ„Ÿåº¦å¾ˆé«˜

- å¦‚æœä»»åŠ¡ç®€å•ï¼ˆå¦‚åƒåœ¾é‚®ä»¶åˆ†ç±»ï¼‰ï¼ŒBoW å°±å¤Ÿã€‚
- å¦‚æœä»»åŠ¡é‡Œæœ‰å¾ˆå¤šå¦å®šã€è½¬æŠ˜ï¼ˆæƒ…æ„Ÿåˆ†æï¼‰ï¼ŒTF-IDF + n-gram å¾€å¾€æ˜æ˜¾æ›´å¥½ã€‚
- å¦‚æœä»»åŠ¡æ¶‰åŠé•¿ä¸Šä¸‹æ–‡æˆ–è¯­ä¹‰ç†è§£ï¼ˆå¦‚é—®ç­”ç³»ç»Ÿï¼‰ï¼ŒBoW/TF-IDF éƒ½ä¼šå¤±æ•ˆï¼Œéœ€è¦ç”¨Â **è¯å‘é‡ (Word2Vec, GloVe)**Â æˆ–Â **Transformer embedding (BERT, GPT embeddings)**ã€‚

---

## 4ï¸âƒ£ æ¨¡å‹æ•ˆæœå·®å¼‚ï¼Œå¯èƒ½å®Œå…¨æ¥è‡ªå‘é‡åŒ–

åœ¨ä½ åˆšè·‘çš„å®éªŒé‡Œï¼Œæ¨¡å‹éƒ¨åˆ†å…¶å®å›ºå®šï¼ˆRandomForest å‚æ•°å·®ä¸å¤šï¼‰ï¼ŒçœŸæ­£èƒ½æ‹‰å¼€å·®è·çš„å°±æ˜¯Â **å‘é‡åŒ–æ–¹æ³•**ï¼š

- BoW vs TF-IDF â†’ ç»“æœå·®åˆ«å¯èƒ½è¾¾åˆ° 5â€“15% çš„å‡†ç¡®ç‡ã€‚
- n-gram èŒƒå›´ä¸åŒ â†’ èƒ½æ•æ‰çŸ­è¯­ä¾èµ–å…³ç³»ï¼ŒF1 æå‡æ˜¾è‘—ã€‚
- max_features å¤ªå°å¯èƒ½ä¸¢ä¿¡æ¯ï¼Œå¤ªå¤§åˆå¯èƒ½è¿‡æ‹Ÿåˆã€‚

---

## 5ï¸âƒ£ å®éªŒå¯¹æ¯”çš„æ„ä¹‰

- **å¯è§£é‡Šæ€§**ï¼šèƒ½çœ‹æ¸…æ¥šå“ªç§å‘é‡åŒ–æ›´é€‚åˆä½ çš„æ•°æ®é›†ã€‚
- **å¯å¤ç°æ€§**ï¼šåœ¨ MLflow é‡Œè®°å½•ä¸‹æ¥ï¼Œåç»­åˆ«äººå¯ä»¥é‡ç°å®éªŒã€‚
- **å·¥ç¨‹è½åœ°**ï¼šå®é™…éƒ¨ç½²æ—¶ï¼Œé€šå¸¸ä¼šé€‰Â **æ•ˆæœæœ€å¥½ä½†å¼€é”€æœ€ä½**Â çš„æ–¹æ³•ï¼ˆæ¯”å¦‚ TF-IDF bigram å¯èƒ½æ¯” BERT embedding è½»é‡å¾ˆå¤šï¼‰ã€‚

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2014.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2015.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2016.png)

1.å¯¹æ¯”accuracyï¼šbowï¼ˆ1ï¼Œ3ï¼‰

2.precision / recal

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2017.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2018.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2019.png)

## å’Œå‰ä¸¤ä¸ªå®éªŒçš„å…³ç³»

- å®éªŒ1ï¼šBoWã€`max_features=10000`ã€è€Œä¸”æ˜¯Â **å…ˆå‘é‡åŒ–å†åˆ‡åˆ†**ï¼ˆæœ‰æ•°æ®æ³„æ¼ï¼‰ â†’ å‚è€ƒä»·å€¼åä½ã€‚
- å®éªŒ2ï¼šç³»ç»Ÿå¯¹æ¯”Â **BoW vs TF-IDF**ï¼Œ`max_features=5000`ï¼Œä¸‰ç§ n-gram(1,1)/(1,2)/(1,3)ï¼Œè€Œä¸”æ˜¯Â **å…ˆåˆ‡åˆ†å† fit å‘é‡å™¨**Â â†’ ç»“æœå¯é ï¼Œå¯æ¨ªå‘æ¯”è¾ƒâ€œæ–¹æ³•+ngramâ€ã€‚
- å®éªŒ3ï¼ˆè¿™æ¬¡ï¼‰ï¼šå›ºå®šÂ **TF-IDF + (1,3)**ï¼Œåªæ”¹å˜Â **`max_features`Â âˆˆ {1kâ€¦10k}**Â â†’ çºµå‘æ¯”è¾ƒâ€œ**ä¿ç•™çš„ç‰¹å¾æ•°**â€å¯¹æ•ˆæœçš„å½±å“ã€‚

## 1)Â `max_features`Â ä¸ºå•¥å½±å“

å®ƒå°±æ˜¯**è¯è¡¨ä¸Šé™**ï¼šåªä¿ç•™å‡ºç°æœ€â€œé‡è¦/å¸¸è§â€çš„å‰ N ä¸ªç‰¹å¾ï¼ˆBoW/TF-IDF ä¼šæŒ‰è¯é¢‘æˆ–ä¿¡æ¯é‡é€‰ï¼‰ã€‚

- **å¤ªå°**
    - ä¿¡æ¯ä¸¢å¤±ï¼šå¾ˆå¤šæœ‰è¾¨è¯†åº¦çš„è¯/çŸ­è¯­è¿›ä¸äº†è¯è¡¨ â†’ æ¨¡å‹çœ‹ä¸åˆ°å…³é”®ä¿¡å·ã€‚
    - ç°è±¡ï¼šè®­ç»ƒå¿«ä½†å‡†ç¡®ç‡/F1 ä¸Šä¸å»ï¼Œå°‘æ•°ç±»å°¤å…¶å·®ã€‚
- **å¤ªå¤§**
    - ç»´åº¦æš´æ¶¨ã€**ç¨€ç–**æ›´ä¸¥é‡ï¼Œè®­ç»ƒæ…¢ã€å†…å­˜é«˜ã€‚
    - **è¿‡æ‹Ÿåˆ**é£é™©å‡é«˜ï¼šéšæœºæ£®æ—/æ ‘æ¨¡å‹åœ¨è¶…é«˜ç»´ç¨€ç–ç©ºé—´å®¹æ˜“å­¦åˆ°å™ªå£°åˆ†è£‚ã€‚
    - è¾¹é™…æ”¶ç›Šé€’å‡ï¼šåŠ åˆ°ä¸€å®šè§„æ¨¡åï¼Œæ–°å¢çš„é•¿å°¾ç‰¹å¾å¤§å¤šæ˜¯å™ªå£°ã€‚
- **æŠ˜ä¸­ç‚¹**
    - å¾€å¾€å­˜åœ¨ä¸€ä¸ªâ€œå¹³å°åŒºâ€ï¼šæ€§èƒ½åŸºæœ¬åˆ°é¡¶ï¼Œå†å¢å¤§åªæ¢æ¥æ›´é«˜æˆæœ¬ã€‚
    - ä½ åœ¨ Exp-3 åšçš„å°±æ˜¯æ‰«Â `max_features`Â æ‰¾è¿™ä¸ªå¹³å°ä½ç½®ã€‚

> å°æ‹›ï¼šé…åˆÂ min_df/max_dfÂ è¿‡æ»¤æç¨€æœ‰æˆ–æå¸¸è§ï¼ˆå¦‚ â€œtheâ€ï¼‰çš„è¯ï¼Œèƒ½æ›´å¿«æ›´å¹²å‡€ã€‚
> 

## 2) n-gramï¼ˆ(1,1)/(1,2)/(1,3)ï¼‰ä¸ºå•¥å½±å“

å®ƒå†³å®š**ç‰¹å¾ç²’åº¦**ï¼šåªçœ‹å•è¯ï¼ˆunigramï¼‰ï¼Œè¿˜æ˜¯æŠŠç›¸é‚»è¯æ‹¼æˆçŸ­è¯­ï¼ˆbigramã€trigramï¼‰ã€‚

- **å¸¦æ¥ä¸Šä¸‹æ–‡/çŸ­è¯­ä¿¡æ¯**
    - â€œgoodâ€ vs â€œnot goodâ€
        - Unigram åªçœ‹è§Â `not`Â å’ŒÂ `good`Â ä¸¤ä¸ªç‹¬ç«‹è¯ï¼Œå®¹æ˜“è¯¯åˆ¤ä¸ºæ­£å‘ã€‚
        - Bigram æ•æ‰åˆ°Â `not good`ï¼Œç›´æ¥ç¼–ç å¦å®šå…³ç³»ï¼Œåˆ¤åˆ«æ›´å‡†ã€‚
    - è¯é¢˜çŸ­è¯­ï¼ˆå¦‚Â `prime minister`,Â `supreme court`ï¼‰å¸¸èƒ½æ˜¾è‘—æå‡å¯åˆ†æ€§ã€‚
- **åŒæ—¶å¢åŠ ç»´åº¦ä¸ç¨€ç–åº¦**
    - n è¶Šå¤§ï¼Œ**ç»„åˆçˆ†ç‚¸**Â â†’ ç‰¹å¾æ•°ä¸ç¨€ç–æ€§æš´æ¶¨ã€‚
    - æ•°æ®ä¸å¤Ÿæ—¶ï¼Œå¾ˆå¤š n-gram åªå‡ºç°å‡ æ¬¡ï¼Œå™ªå£°/è¿‡æ‹Ÿåˆé£é™©ä¸Šå‡ã€‚
- **ç»éªŒ**
    - (1,2) å¾€å¾€æ˜¯æ€§ä»·æ¯”æœ€é«˜ï¼šå…¼é¡¾è¯ä¸çŸ­è¯­ã€‚
    - (1,3) å¯èƒ½æ›´å¥½ï¼Œä½†éœ€è¦**æ›´å¤šæ ·æœ¬**å’Œ**æ›´é«˜çš„Â `max_features`**Â æ‰ä¸è‡³äºâ€œç¨€è–„â€

```python
# Step 1: Function to run the experiment
def run_experiment_tfidf_max_features(max_features):
    ngram_range = (1, 3)  # Trigram setting

    # Step 2: Vectorization using TF-IDF with varying max_features
    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)

    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])

    X_train = vectorizer.fit_transform(X_train)
    X_test = vectorizer.transform(X_test)

    # Step 4: Define and train a Random Forest model
    with mlflow.start_run() as run:
        # Set tags for the experiment and run
        mlflow.set_tag("mlflow.runName", f"TFIDF_Trigrams_max_features_{max_features}")
        mlflow.set_tag("experiment_type", "feature_engineering")
        mlflow.set_tag("model_type", "RandomForestClassifier")

        # Add a description
        mlflow.set_tag("description", f"RandomForest with TF-IDF Trigrams, max_features={max_features}")

        # Log vectorizer parameters
        mlflow.log_param("vectorizer_type", "TF-IDF")
        mlflow.log_param("ngram_range", ngram_range)
        mlflow.log_param("vectorizer_max_features", max_features)

        # Log Random Forest parameters
        n_estimators = 200
        max_depth = 15

        mlflow.log_param("n_estimators", n_estimators)
        mlflow.log_param("max_depth", max_depth)

        # Initialize and train the model
        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
        model.fit(X_train, y_train)

        # Step 5: Make predictions and log metrics
        y_pred = model.predict(X_test)

        # Log accuracy
        accuracy = accuracy_score(y_test, y_pred)
        mlflow.log_metric("accuracy", accuracy)

        # Log classification report
        classification_rep = classification_report(y_test, y_pred, output_dict=True)
        for label, metrics in classification_rep.items():
            if isinstance(metrics, dict):
                for metric, value in metrics.items():
                    mlflow.log_metric(f"{label}_{metric}", value)

        # Log confusion matrix
        conf_matrix = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        plt.title(f"Confusion Matrix: TF-IDF Trigrams, max_features={max_features}")
        plt.savefig("confusion_matrix.png")
        mlflow.log_artifact("confusion_matrix.png")
        plt.close()

        # Log the model
        mlflow.sklearn.log_model(model, f"random_forest_model_tfidf_trigrams_{max_features}")

# Step 6: Test various max_features values
max_features_values = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]

for max_features in max_features_values:
    run_experiment_tfidf_max_features(max_features)
    
    
    è®¾äº†10ä¸ªå‚æ•°æ‰€ä»¥å°±æœ‰10è¡Œ
```

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2020.png)

### **Step 1: n-gram è®¾å®š**

```python
ngram_range = (1, 3)  # Trigram setting

```

- è¡¨ç¤ºç”¨Â **1-gram, 2-gram, 3-gram**Â ä¸€èµ·åšç‰¹å¾ã€‚
- e.g.Â `"I love pizza"`Â â†’Â `["I", "love", "pizza", "I love", "love pizza", "I love pizza"]`

---

### **Step 2: å‘é‡åŒ– (TF-IDF)**

```python
vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)

```

- `TfidfVectorizer`ï¼šæŠŠæ–‡æœ¬è½¬æˆ TF-IDF æƒé‡çŸ©é˜µã€‚
- `ngram_range=(1,3)`ï¼šåŒ…å« unigramã€bigramã€trigramã€‚
- `max_features`ï¼šåªä¿ç•™å‰ N ä¸ªæœ€é‡è¦çš„ç‰¹å¾ã€‚

---

### **Step 3: æ•°æ®åˆ’åˆ†**

```python
X_train, X_test, y_train, y_test = train_test_split(
    df['clean_comment'], df['category'],
    test_size=0.2, random_state=42, stratify=df['category']
)

```

- æ•°æ®åˆ†æˆ 80% è®­ç»ƒé›†ï¼Œ20% æµ‹è¯•é›†ã€‚
- `stratify=y`Â ä¿è¯ç±»åˆ«åˆ†å¸ƒä¸€è‡´ã€‚

ç„¶åæŠŠæ–‡æœ¬è½¬æˆ TF-IDF å‘é‡ï¼š

```python
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

```

---

### **Step 4: æ¨¡å‹è®­ç»ƒ + MLflow Tracking**

```python
with mlflow.start_run() as run:

```

- å¼€å¯ä¸€ä¸ª MLflow è¿è¡Œï¼Œæ¯æ¬¡å®éªŒéƒ½ä¼šå•ç‹¬å­˜æ¡£ã€‚

è®°å½•å…ƒä¿¡æ¯ï¼š

```python
mlflow.set_tag("mlflow.runName", f"TFIDF_Trigrams_max_features_{max_features}")
mlflow.set_tag("experiment_type", "feature_engineering")
mlflow.set_tag("model_type", "RandomForestClassifier")
mlflow.set_tag("description", f"RandomForest with TF-IDF Trigrams, max_features={max_features}")

```

- æ–¹ä¾¿ä½ åœ¨ MLflow UI é‡ŒæŸ¥é˜…ã€‚

è®°å½•å‚æ•°ï¼š

```python
mlflow.log_param("vectorizer_type", "TF-IDF")
mlflow.log_param("ngram_range", ngram_range)
mlflow.log_param("vectorizer_max_features", max_features)
mlflow.log_param("n_estimators", 200)
mlflow.log_param("max_depth", 15)

```

- æŠŠç‰¹å¾é€‰æ‹©å’Œæ¨¡å‹çš„å…³é”®å‚æ•°éƒ½å­˜ä¸‹æ¥ã€‚

è®­ç»ƒæ¨¡å‹ï¼š

```python
model = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42)
model.fit(X_train, y_train)

```

---

### **Step 5: æ¨¡å‹è¯„ä¼° + è®°å½•ç»“æœ**

é¢„æµ‹ï¼š

```python
y_pred = model.predict(X_test)

```

è¯„ä¼°ï¼š

```python
accuracy = accuracy_score(y_test, y_pred)
mlflow.log_metric("accuracy", accuracy)

```

- è®°å½• Accuracyã€‚

åˆ†ç±»æŠ¥å‘Šï¼š

```python
classification_rep = classification_report(y_test, y_pred, output_dict=True)
for label, metrics in classification_rep.items():
    if isinstance(metrics, dict):
        for metric, value in metrics.items():
            mlflow.log_metric(f"{label}_{metric}", value)

```

- è®°å½• Precisionã€Recallã€F1 ç­‰æŒ‡æ ‡ï¼ˆå¯¹æ¯ä¸ªç±»åˆ«å•ç‹¬ä¿å­˜ï¼‰ã€‚

æ··æ·†çŸ©é˜µï¼š

```python
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.savefig("confusion_matrix.png")
mlflow.log_artifact("confusion_matrix.png")

```

- ç”»æ··æ·†çŸ©é˜µå¹¶ä¿å­˜åˆ° MLflowã€‚

ä¿å­˜æ¨¡å‹ï¼š

```python
mlflow.sklearn.log_model(model, f"random_forest_model_tfidf_trigrams_{max_features}")

```

- æŠŠè®­ç»ƒå¥½çš„æ¨¡å‹å­˜æ¡£åˆ° MLflowã€‚

---

### **Step 6: å¾ªç¯ä¸åŒ max_features**

```python
max_features_values = [1000,2000,...,10000]

for max_features in max_features_values:
    run_experiment_tfidf_max_features(max_features)

```

- è‡ªåŠ¨è·‘ 10 æ¬¡å®éªŒï¼šä» 1000 ç‰¹å¾ â†’ 10000 ç‰¹å¾ã€‚
- æ¯æ¬¡éƒ½ä¼šåœ¨ MLflow UI ç”Ÿæˆä¸€æ¡ runï¼Œæ–¹ä¾¿æ¨ªå‘å¯¹æ¯”ã€‚

---

## ğŸ¯ æ€»ç»“ä½œç”¨

1. **æ ¸å¿ƒå˜é‡ï¼š`max_features`**Â â†’ æ§åˆ¶ç‰¹å¾æ•°é‡ã€‚
2. **ä¿æŒéšæœºæ£®æ—å‚æ•°ä¸å˜**Â â†’ è®©ä½ æ¸…æ¥šçœ‹åˆ° TF-IDF è¯è¡¨å¤§å°å¯¹æ€§èƒ½çš„å½±å“ã€‚
3. **MLflow è®°å½•å…¨æµç¨‹**Â â†’ æ–¹ä¾¿å®éªŒå¯å¤ç°ã€å¯å¯¹æ¯”ã€‚

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2021.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2022.png)

ç¬¬å››ä¸ªå®éªŒ

è¿™æ®µä»£ç æ˜¯åœ¨Â **åŒä¸€ä»½é¢„å¤„ç†åçš„æ–‡æœ¬æ•°æ®**Â ä¸Šï¼Œç”¨Â **ç›¸åŒç‰¹å¾ï¼ˆTF-IDF ä¸‰å…ƒgramã€10k è¯è¡¨ï¼‰+ ç›¸åŒæ¨¡å‹ï¼ˆRFï¼‰**ï¼Œå¯¹æ¯”Â **äº”ç§å¤„ç†ç±»åˆ«ä¸å‡è¡¡çš„ç­–ç•¥**ï¼Œå¹¶æŠŠæ¯æ¬¡è®­ç»ƒçš„å‚æ•°ã€æŒ‡æ ‡ã€æ··æ·†çŸ©é˜µã€æ¨¡å‹ç»Ÿç»Ÿè®°å½•åˆ°Â **MLflow**ï¼Œæ–¹ä¾¿ä½ åœ¨ Web UI é‡Œæ¨ªå‘æ¯”è¾ƒï¼Œé€‰æ‹©æœ€åˆé€‚çš„æ–¹æ³•ã€‚

- **Exp 2**ï¼šå‘é‡åŒ–æ–¹å¼ & n-gram è°æ›´å¥½ï¼Ÿ
- **Exp 3**ï¼šTF-IDF ä¸‹è¯è¡¨å¤šå¤§æœ€å¥½ï¼Ÿ
- **Exp 4ï¼ˆç°åœ¨ï¼‰**ï¼šåœ¨å›ºå®šç‰¹å¾ä¸æ¨¡å‹ä¸‹ï¼Œ**å“ªç§ä¸å‡è¡¡å¤„ç†**èƒ½è®©å°ç±»è¡¨ç°ï¼ˆmacro-F1ã€å°‘æ•°ç±» recallï¼‰æœ€å¥½ã€‚
1. ç›®æ ‡ä¸åŒ
- **Baselineï¼ˆæœ€æ—©é‚£æ¬¡ï¼‰**ï¼šåšä¸€ä¸ªéšæœºæ£®æ—åŸºçº¿ï¼›è€Œä¸”ä½ å…ˆæŠŠå…¨é‡æ–‡æœ¬ BoW å‘é‡åŒ–å†åˆ‡åˆ†ï¼ˆæœ‰è½»å¾®æ•°æ®æ³„éœ²é£é™©ï¼‰ã€‚
- **Exp 2 â€“ BoW vs TF-IDF**ï¼šåŒä¸€ä»½é¢„å¤„ç†åçš„ CSVï¼Œä¸Šæ¯”è¾ƒÂ **å‘é‡åŒ–æ–¹å¼**ï¼ˆBoW vs TF-IDFï¼‰+Â **n-gram**(1,1)/(1,2)/(1,3)ã€‚
- **Exp 3 â€“ TF-IDF max_features**ï¼šå›ºå®šÂ **TF-IDF + ä¸‰å…ƒç»„(1,3)**ï¼Œåªæ¯”è¾ƒÂ **è¯è¡¨å¤§å° max_features**ï¼ˆ1000â†’10000ï¼‰ã€‚
- **Exp 4 â€“ Imbalanced**ï¼ˆå½“å‰ï¼‰ï¼šå›ºå®šÂ **TF-IDF + ä¸‰å…ƒç»„(1,3) + max_features=10000 + åŒä¸€éšæœºæ£®æ—**ï¼Œåªæ¯”è¾ƒÂ **ä¸å‡è¡¡å¤„ç†ç­–ç•¥**ï¼š
    - `class_weight='balanced'`
    - è®­ç»ƒé›†ä¸ŠÂ **SMOTE**Â è¿‡é‡‡æ ·
    - **ADASYN**Â è¿‡é‡‡æ ·
    - **RandomUnderSampler**Â ä¸‹é‡‡æ ·
    - **SMOTEENN**ï¼ˆSMOTE+ENN æ¸…å™ªï¼‰

### 1. ç°å®ä¸­çš„æ•°æ®é€šå¸¸ä¸å‡è¡¡

æ¯”å¦‚ä½ çš„ reddit æ•°æ®ï¼ŒæŸäº›ç±»åˆ«çš„æ ·æœ¬æ•°é‡å¯èƒ½ç‰¹åˆ«å¤šï¼Œè€ŒæŸäº›ç±»åˆ«åªæœ‰å¾ˆå°‘ã€‚

- å¦‚æœç›´æ¥è®­ç»ƒï¼Œæ¨¡å‹ä¼šåå‘äºâ€œå¤šæ•°ç±»â€ã€‚
- åœ¨åˆ†ç±»æŠ¥å‘Šé‡Œä½ ä¼šçœ‹åˆ°ï¼šaccuracy å¾ˆé«˜ï¼Œä½†å°ç±»åˆ«çš„ recall/F1 éå¸¸å·®ã€‚

---

### 2. ä¸åŒç­–ç•¥ä¼šå½±å“æ¨¡å‹â€œæ˜¯å¦å…³æ³¨å°‘æ•°ç±»â€

å¸¸è§æ‰‹æ®µï¼š

- **class_weight="balanced"**ï¼šç»™å°‘æ•°ç±»æ›´é«˜çš„æƒé‡ï¼Œè®©æ¨¡å‹åœ¨æŸå¤±å‡½æ•°ä¸Šæ›´é‡è§†å®ƒã€‚
- **SMOTE / ADASYN**ï¼šäººä¸ºâ€œé€ â€ä¸€äº›å°‘æ•°ç±»æ ·æœ¬ï¼ˆè¿‡é‡‡æ ·ï¼‰ï¼Œç¼“è§£æ•°é‡å·®è·ã€‚
- **RandomUnderSampler**ï¼šåˆ æ‰éƒ¨åˆ†å¤šæ•°ç±»æ ·æœ¬ï¼Œç¼©å°å·®è·ã€‚
- **SMOTEENN**ï¼šç»“åˆè¿‡é‡‡æ ·+æ¸…ç†å™ªå£°ï¼Œå¹³è¡¡åŒæ—¶é¿å…ç”Ÿæˆå¤ªå¤šåƒåœ¾æ ·æœ¬ã€‚

ä¸åŒæ–¹æ³•çš„æ•ˆæœå¯èƒ½å®Œå…¨ä¸ä¸€æ ·ï¼š

- æœ‰çš„æå‡ recallï¼Œä½† precision ä¸‹é™ â†’ é¢„æµ‹å°ç±»æ›´å¤šï¼Œä½†ä¹Ÿå®¹æ˜“è¯¯æŠ¥ã€‚
- æœ‰çš„æå‡ macro-F1ï¼Œæ€»ä½“æ›´å¹³è¡¡ã€‚
- æœ‰çš„ï¼ˆå¦‚ç®€å•ä¸‹é‡‡æ ·ï¼‰å¯èƒ½ accuracy é™ä½ï¼Œä½†å…¬å¹³æ€§æ›´å¥½ã€‚

---

### 3. å¯¹æ¯”çš„æ„ä¹‰

- **æ‰¾åˆ° trade-off**ï¼šåˆ°åº•è¦ accuracy é«˜ï¼Œè¿˜æ˜¯è¦æ¯ä¸ªç±»éƒ½å…¬å¹³ï¼ˆmacro-F1 é«˜ï¼‰ã€‚
- **æŒ‡å¯¼åç»­å®éªŒ**ï¼šå¦‚æœæŸç±»ä»»åŠ¡å¾ˆä¾èµ– recallï¼ˆä¾‹å¦‚æ¬ºè¯ˆæ£€æµ‹ã€åŒ»ç–—é¢„è­¦ï¼‰ï¼Œå°±è¦ä¼˜å…ˆæŒ‘ recall æœ€å¥½çš„ç­–ç•¥ã€‚
- **é¿å…â€œå‡é«˜åˆ†â€**ï¼šå¦‚æœåªçœ‹ accuracyï¼Œå¤šæ•°ç±»æ’‘èµ·æ¥çš„é«˜åˆ†å…¶å®æ¯«æ— æ„ä¹‰ã€‚

---

### 4. æ”¾åœ¨ä½ å®éªŒçš„è¯­å¢ƒé‡Œ

å‰ä¸¤ä¸ªå®éªŒï¼ˆBoW/TF-IDFã€max_featuresï¼‰è§£å†³çš„æ˜¯â€œ**æ–‡æœ¬æ€ä¹ˆè¡¨ç¤º**â€ï¼›

è€Œè¿™ä¸ªå®éªŒè§£å†³çš„æ˜¯â€œ**ç±»åˆ«ä¸å¹³è¡¡æ€ä¹ˆå¤„ç†**â€ã€‚

è¿™æ ·ä½ æ‰èƒ½ç¡®è®¤ï¼šæ¨¡å‹æ€§èƒ½å·®å¼‚ä¸æ˜¯å› ä¸ºÂ **ç‰¹å¾è¡¨ç¤ºçš„é—®é¢˜**ï¼Œè€Œæ˜¯å› ä¸ºÂ **æ•°æ®åˆ†å¸ƒçš„é—®é¢˜**ã€‚

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2023.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2024.png)

ç¬¬äº”ä¸ªå®éªŒï¼š

1. å®‰è£… & é…ç½®
- `pip install mlflow boto3 awscli optuna xgboost imbalanced-learn`Â è£…å®éªŒè¿½è¸ªã€è¶…å‚æœç´¢ã€æ¨¡å‹ä¸ä¸å‡è¡¡å¤„ç†å·¥å…·ã€‚
- `aws configure`Â é…ç½® S3 å‡­è¯ï¼ˆâš ï¸ ä½ æŠŠ AK/SK ç²˜å‡ºæ¥äº†ï¼Œå¼ºçƒˆå»ºè®®ç«‹åˆ»åœ¨ AWS ä¸Š**æ—‹è½¬å¯†é’¥**å¹¶æ”¹ç”¨ç¯å¢ƒå˜é‡ï¼Œè€Œä¸æ˜¯æ˜æ–‡å†™/äº¤äº’å¼è¾“å…¥ï¼‰ã€‚
- `mlflow.set_tracking_uri(...)`Â æŠŠ MLflow çš„è¿½è¸ªæŒ‡å‘ä½ è¿œç«¯çš„ tracking serverã€‚
1. å‡†å¤‡æ•°æ®ä¸æ–‡æœ¬ç‰¹å¾
- è¯»Â `reddit_preprocessing.csv`ï¼›æŠŠæ ‡ç­¾ä»Â `{-1,0,1}`Â æ”¹æˆÂ `{2,0,1}`ï¼›train/test åˆ‡åˆ†ï¼ˆ`stratify`Â ä¿è¯å„ç±»æ¯”ä¾‹ç¨³å®šï¼‰ã€‚
- ç”¨Â **TF-IDF**Â åš (1,3) çš„ n-gramï¼Œ`max_features=10000`ï¼Œåªåœ¨è®­ç»ƒé›†ä¸ŠÂ `fit`ï¼Œå† transform æµ‹è¯•é›†ï¼ˆé¿å…æ•°æ®æ³„æ¼ï¼‰ã€‚
- ç”¨Â **SMOTE**Â åªåœ¨è®­ç»ƒé›†ä¸Šåšè¿‡é‡‡æ ·ï¼Œå¹³è¡¡ç±»åˆ«ã€‚
1. å®šä¹‰é€šç”¨çš„ MLflow è®°å½•å‡½æ•°
- è®­ç»ƒä¼ å…¥çš„æ¨¡å‹â†’é¢„æµ‹â†’è®°å½•Â `accuracy`Â +Â `classification_report`Â å„ç±»åˆ«çš„ precision/recall/f1 åˆ° MLflowï¼Œå¹¶æŠŠæ¨¡å‹ä»¥Â `mlflow.sklearn.log_model`Â å½¢å¼ä¿å­˜ã€‚
1. ç”¨Â **Optuna**Â ç»™ XGBoost åšè¶…å‚æœç´¢
- ç›®æ ‡å‡½æ•°é‡Œå¯¹æ¯ä¸ª trial é‡‡æ ·Â `n_estimators / learning_rate / max_depth`ï¼Œè®­ç»ƒÂ `XGBClassifier`ï¼Œè¿”å›åœ¨**å›ºå®šæµ‹è¯•é›†**ä¸Šçš„Â `accuracy`ã€‚
- `study.optimize(..., n_trials=30)`Â å¼€å§‹è¯•éªŒï¼›ä½ æ—¥å¿—é‡Œèƒ½çœ‹åˆ°æ¯ä¸ª trial çš„å¾—åˆ†ï¼Œä¾‹å¦‚ Trial 4 å¾—åˆ° ~0.772 çš„ accuracyï¼Œæ˜¯ç›®å‰æœ€ä½³ã€‚
- ç»“æŸååªç”¨Â **æœ€ä¼˜è¶…å‚**Â æ„å»ºä¸€ä¸ª XGBoost æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¸Šé¢çš„Â `log_mlflow`Â è®°å½•åˆ° MLflowï¼ˆRun nameï¼š`XGBoost_SMOTE_TFIDF_Trigrams`ï¼‰ã€‚
1. ä½ çœ‹åˆ°çš„æŠ¥é”™/ä¸­æ–­
- `KeyboardInterrupt`Â å‡ºç°åœ¨ Trial 13ï¼Œè¯´æ˜ç¬¬ 13 æ¬¡è¯•éªŒè®­ç»ƒè€—æ—¶è¾ƒé•¿ï¼Œä½ æ‰‹åŠ¨ä¸­æ–­äº†ï¼ˆæˆ–ä¼šè¯è¶…æ—¶ï¼‰ã€‚è¿™ä¸ä¼šå½±å“å‰é¢å·²å®Œæˆçš„ trialï¼Œå®ƒä»¬å·²ç»è®°å½•åœ¨å†…ï¼ˆä½†å¦‚æœ MLflow UI é‡Œæ²¡çœ‹åˆ°æ–° runï¼Œå¯èƒ½æ˜¯ tracking URI æŒ‡å‘çš„ä¸æ˜¯ä½ ç°åœ¨å¼€çš„æœåŠ¡å™¨ï¼Œæˆ–æµè§ˆçš„æ˜¯åˆ«çš„ Experimentï¼‰ã€‚

ç”¨ TF-IDF(1â€“3gram, 10kç‰¹å¾) + SMOTE ä½œä¸ºå›ºå®šç‰¹å¾å·¥ç¨‹ï¼Œå¯¹Â **XGBoost**Â çš„å…³é”®è¶…å‚åšÂ **Optuna**Â æœç´¢ï¼›æŠŠ**æœ€ä¼˜æ¨¡å‹**ä»¥åŠæ¯ä¸ªæ¨¡å‹çš„æŒ‡æ ‡ä¸Šä¼ åˆ°Â **MLflow**Â ä»¥ä¾¿å¯¹æ¯”ã€‚

- å‰é¢ä¸‰ç»„ï¼ˆExp2/3/4ï¼‰æ˜¯åœ¨**åŒä¸€ç±»æ¨¡å‹ï¼ˆRFï¼‰**ä¸‹ï¼Œåˆ†åˆ«æ¯”è¾ƒâ€œå‘é‡åŒ–æ–¹å¼ / ç‰¹å¾ç»´åº¦ / ä¸å‡è¡¡å¤„ç†â€ã€‚
- æœ€æ–°è¿™ç»„ï¼ˆ**Exp5**ï¼‰æŠŠå…³æ³¨ç‚¹è½¬åˆ°**æ¨¡å‹ä¸è¶…å‚**ï¼ˆXGBoost + Optunaï¼‰ï¼Œç‰¹å¾å·¥ç¨‹å’Œä¸å‡è¡¡å¤„ç†å›ºå®šä¸º TF-IDF(1,3,10000) + SMOTEï¼Œä»…è®°å½•**æœ€ä½³**ç»“æœåˆ° MLflowã€‚

sorry ä¸è·‘äº†

ç¬¬å…­ä¸ª

**åœ¨å›ºå®šçš„æ–‡æœ¬è¡¨ç¤ºï¼ˆTF-IDFï¼Œ1-3gramï¼Œmax_features=1000ï¼‰+ SMOTE çš„å‰æä¸‹ï¼Œç”¨ Optuna ç»™ LightGBM åšè¶…å‚æ•°æœç´¢ï¼Œå¹¶æŠŠæ¯ä¸ª trial ä½œä¸ºä¸€æ¬¡ MLflow run è®°å½•ä¸‹æ¥**ã€‚ç›®æ ‡æ˜¯çœ‹çœ‹Â **LightGBM+è°ƒå‚**Â èƒ½å¦æ¯”ä½ å‰é¢é‚£äº›å›ºå®šæ¨¡å‹/å›ºå®šå‚æ•°ï¼ˆRandomForestã€TF-IDF å‚æ•°ç½‘æ ¼ã€å„ç±»ä¸å‡è¡¡å¤„ç†ã€ä»¥åŠç¬¬5ä¸ªå®éªŒçš„ XGBoost+Optunaï¼‰æ›´å¥½ã€‚

# ä»£ç åœ¨åšä»€ä¹ˆï¼ˆé€æ­¥ï¼‰

1. **æ ‡ç­¾é‡æ˜ å°„**ï¼šæŠŠ {-1,0,1} â†’ {2,0,1}ï¼Œé¿å…è´Ÿæ•°æ ‡ç­¾ï¼ˆæœ‰äº›åº“ä¸å–œæ¬¢è´Ÿæ ‡ç­¾ï¼‰ã€‚
2. **å‘é‡åŒ–**ï¼š`TfidfVectorizer(ngram_range=(1,3), max_features=1000)`Â æŠŠæ–‡æœ¬è½¬æˆç¨€ç–ç‰¹å¾ã€‚
3. **SMOTE ä¸Šé‡‡æ ·**ï¼šç”¨å°‘æ•°ç±»åˆæˆæ ·æœ¬æ¥å¹³è¡¡ç±»åˆ«ã€‚
4. **åˆ‡åˆ†æ•°æ®**ï¼šå°†å¹³è¡¡åçš„æ•°æ®æŒ‰ 8/2 åˆ‡åˆ†æˆè®­ç»ƒ/æµ‹è¯•é›†ã€‚
5. **Optuna è°ƒå‚ LightGBM**ï¼šæœç´¢å¦‚Â `n_estimatorsã€learning_rateã€max_depthã€num_leavesã€min_child_samplesã€colsample_bytreeã€subsampleã€reg_alphaã€reg_lambda`Â ç­‰ï¼›
    
    æ¯ä¸ª trialï¼š
    
    - ç”Ÿæˆä¸€ä¸ª LGBMClassifierï¼›
    - è®­ç»ƒå¹¶åœ¨æµ‹è¯•é›†ä¸Šç®— accuracyï¼›
    - **ç”¨ MLflow è®°å½•**å‚æ•°ã€å‡†ç¡®ç‡ã€åˆ†ç±»æŠ¥å‘Šã€å¹¶ä¿å­˜æ¨¡å‹ã€‚
6. **å®Œæˆå**ï¼šç”¨ Optuna çš„å¯è§†åŒ–çœ‹Â **å‚æ•°é‡è¦æ€§**Â å’ŒÂ **ä¼˜åŒ–å†å²**ï¼Œå¹¶æŠŠÂ **best_params**Â å†è®­ç»ƒä¸€æ¬¡ï¼Œä½œä¸ºâ€œæœ€ä½³æ¨¡å‹â€è®°å½•åˆ° MLflowã€‚

# å’Œå‰é¢çš„å®éªŒæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

- **å¯¹è±¡ä¸åŒ**ï¼š
    - å‰é¢ 1~3ï¼šå¯¹æ¯”â€œå‘é‡åŒ–æ–¹å¼/è¶…å‚æ•°â€ï¼ˆBoW vs TF-IDFã€n-gramã€max_featuresï¼‰ã€‚
    - ç¬¬4ï¼šå¯¹æ¯”**ä¸å‡è¡¡å¤„ç†ç­–ç•¥**ï¼ˆclass_weightã€SMOTE/ADASYN/Under/SMOTEENNï¼‰ã€‚
    - ç¬¬5ï¼šå…ˆé”å®šâ€œå‘é‡åŒ–+SMOTEâ€ï¼Œå¯¹Â **XGBoost**Â åš Optuna è°ƒå‚ã€‚
    - **ç¬¬6ï¼ˆå½“å‰ï¼‰**ï¼šåŒæ ·é”å®šâ€œå‘é‡åŒ–+SMOTEâ€ï¼Œä½†æŠŠç®—æ³•æ¢æˆÂ **LightGBM**Â å¹¶è°ƒå‚ï¼Œå¯¹æ¯”Â **XGBoost vs LightGBM**Â å“ªä¸ªåœ¨ä½ è¿™ä¸ªæ–‡æœ¬ä»»åŠ¡ä¸Šæ›´å¼ºã€ç”¨ä»€ä¹ˆå‚æ•°æœ€å¥½ã€‚
- **æœç´¢ç©ºé—´ä¸åŒ**ï¼šXGBoost å’Œ LightGBM çš„å…³é”®è¶…å‚ä¸ä¸€æ ·ï¼ˆæ¯”å¦‚ LGBM çš„Â `num_leavesã€min_child_samples`Â ç­‰ï¼‰ã€‚
- **å®éªŒç›®çš„**ï¼šå‰é¢æ˜¯åœ¨æ‰¾**ç‰¹å¾è¡¨ç¤º/æ•°æ®å¤„ç†**çš„æœ€ä½³ç»„åˆï¼›ç¬¬5/6æ˜¯åœ¨åŒä¸€ç‰¹å¾ä¸é‡‡æ ·ç­–ç•¥ä¸‹ï¼Œæ¯”è¾ƒ**ä¸åŒæ¢¯åº¦æå‡æ¡†æ¶+è°ƒå‚**çš„ä¸Šé™è¡¨ç°ã€‚

ä½ä¸ƒä¸ª

### ğŸ”¹å‰ä¸€ä¸ªå®éªŒï¼ˆç¬¬å…­ä¸ªï¼‰

- **ç›®æ ‡**ï¼šç”¨ Optuna è¶…å‚æ•°æœç´¢ï¼Œæ‰¾åˆ°æœ€ä¼˜çš„ LightGBM å‚æ•°ã€‚
- **é‡ç‚¹**ï¼š
    - åªç”¨Â **LightGBM**Â ä½œä¸ºæ¨¡å‹ã€‚
    - é€šè¿‡Â **Optuna**Â ä¸æ–­è¯•ä¸åŒå‚æ•°ç»„åˆï¼ˆn_estimators, learning_rate, num_leaves, etc.ï¼‰ã€‚
    - ç”¨Â **SMOTE**Â åšç±»åˆ«å¹³è¡¡ã€‚
    - ç”¨Â **MLflow**Â è®°å½•æ¯æ¬¡å®éªŒï¼ˆå‚æ•°ã€æŒ‡æ ‡ã€æ¨¡å‹ï¼‰ã€‚
    - ç»“æœæ˜¯ â†’ æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„ LightGBM é…ç½®ã€‚

æ¢å¥è¯è¯´ï¼Œè¿™ä¸ªå®éªŒæ˜¯åœ¨ã€Œè°ƒå‚ + å•æ¨¡å‹ä¼˜åŒ–ã€ã€‚

---

### ğŸ”¹ä½ ç°åœ¨çš„å®éªŒï¼ˆStackingï¼‰

- **ç›®æ ‡**ï¼šç”¨é›†æˆå­¦ä¹ ï¼ˆStackingï¼‰æå‡æ¨¡å‹è¡¨ç°ã€‚
- **é‡ç‚¹**ï¼š
    - ä½¿ç”¨Â **å¤šä¸ªåŸºæ¨¡å‹ (base learners)**ï¼šLightGBM + Logistic Regressionã€‚
    - ä½¿ç”¨Â **ä¸€ä¸ªå…ƒå­¦ä¹ å™¨ (meta learner)**ï¼šKNNã€‚
    - è®­ç»ƒæ–¹å¼æ˜¯ï¼š
        - Base models å…ˆå­¦ä¹ ç‰¹å¾ã€‚
        - Meta learnerï¼ˆKNNï¼‰å†åŸºäº base models çš„é¢„æµ‹ç»“æœæ¥åšæœ€ç»ˆé¢„æµ‹ã€‚
    - è¿™é‡Œæ²¡æœ‰ç”¨ SMOTEã€æ²¡æœ‰ç”¨ Optunaã€ä¹Ÿæ²¡æœ‰è®°å½•åˆ° MLflowã€‚
    - ç»“æœæ˜¯ â†’ ç”¨ç»„åˆæ¨¡å‹æ¥è¯•è¯•èƒ½ä¸èƒ½æ¯”å•ä¸€ LightGBM æ•ˆæœæ›´å¥½ã€‚

## ğŸ§ª å®éªŒ 1ï¼šæ–‡æœ¬å‘é‡åŒ–å¯¹æ¯”ï¼ˆBoW vs TF-IDFï¼Œä¸åŒ n-gramï¼‰

- **åšäº†ä»€ä¹ˆ**
    - ç”¨ BoWï¼ˆè¯è¢‹æ¨¡å‹ï¼‰å’Œ TF-IDF ä¸¤ç§æ–¹å¼è¡¨ç¤ºæ–‡æœ¬ã€‚
    - å°è¯•äº† unigramã€bigramã€trigram ä¸‰ç§ n-gram è®¾ç½®ã€‚
    - ç”¨ RandomForest åšåˆ†ç±»ã€‚
- **ç›®çš„**
    - å¯¹æ¯”æ–‡æœ¬å‘é‡åŒ–æ–¹æ³•å’Œ n-gram èŒƒå›´å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚
- **åŒºåˆ«**
    - è¿™æ˜¯æœ€åŸºç¡€çš„å®éªŒï¼Œæ ¸å¿ƒå…³æ³¨Â **ç‰¹å¾å·¥ç¨‹ï¼ˆæ–‡æœ¬è¡¨ç¤ºæ–¹æ³•ï¼‰**ã€‚

---

## ğŸ§ª å®éªŒ 2ï¼šå›ºå®š n-gramï¼Œå¯¹æ¯” max_featuresï¼ˆç‰¹å¾æ•°é‡ï¼‰

- **åšäº†ä»€ä¹ˆ**
    - ä½¿ç”¨ TF-IDF + trigramã€‚
    - æ”¹å˜Â `max_features`ï¼ˆ1000â€“10000ï¼‰ï¼Œé™åˆ¶è¯æ±‡è¡¨å¤§å°ã€‚
- **ç›®çš„**
    - è§‚å¯Ÿé«˜ç»´ç‰¹å¾ vs é™åˆ¶ç»´åº¦æ—¶æ¨¡å‹è¡¨ç°çš„å·®å¼‚ã€‚
- **åŒºåˆ«**
    - è¿˜æ˜¯ RandomForestï¼Œä½†è¿™æ¬¡å…³æ³¨çš„æ˜¯Â **ç‰¹å¾æ•°é‡å¯¹æ€§èƒ½çš„å½±å“**ã€‚

---

## ğŸ§ª å®éªŒ 3ï¼šå¤„ç†ç±»åˆ«ä¸å‡è¡¡ï¼ˆClass weightsã€Oversamplingã€SMOTEã€ADASYN ç­‰ï¼‰

- **åšäº†ä»€ä¹ˆ**
    - åœ¨ TF-IDF åŸºç¡€ä¸Šï¼Œç”¨ä¸åŒçš„ä¸å‡è¡¡å¤„ç†ç­–ç•¥ã€‚
    - å†ç”¨ RandomForest è®­ç»ƒã€‚
- **ç›®çš„**
    - è§£å†³ â€œå¤šæ•°ç±»å‹åˆ¶å°‘æ•°ç±»â€ çš„é—®é¢˜ï¼Œé¿å…æ¨¡å‹åªé¢„æµ‹å¤§ç±»ã€‚
- **åŒºåˆ«**
    - å‰ä¸¤ä¸ªå®éªŒé»˜è®¤æ•°æ®åˆ†å¸ƒä¸å˜ï¼Œè¿™ä¸ªå®éªŒå¼€å§‹å…³æ³¨Â **æ•°æ®å±‚é¢çš„å¹³è¡¡**ã€‚

---

## ğŸ§ª å®éªŒ 4ï¼šåœ¨ MLflow ä¸­è®°å½•ä¸å‡è¡¡å®éªŒ

- **åšäº†ä»€ä¹ˆ**
    - æŠŠå®éªŒ 3 çš„å„ç§ä¸å‡è¡¡ç­–ç•¥ï¼ˆclass weightã€oversamplingã€SMOTE+ENN ç­‰ï¼‰è¿è¡Œç»“æœå†™å…¥ MLflowã€‚
- **ç›®çš„**
    - ä¸åªæ˜¯è·‘å®éªŒï¼Œè¿˜è¦æŠŠç»“æœç³»ç»ŸåŒ–ç®¡ç†å’Œå¯¹æ¯”ã€‚
- **åŒºåˆ«**
    - å’Œå®éªŒ 3 çš„æŠ€æœ¯å†…å®¹ç±»ä¼¼ï¼Œä½†å¢åŠ äº†Â **å®éªŒè¿½è¸ªå’Œå¯è§†åŒ–ç®¡ç†**ã€‚

---

## ğŸ§ª å®éªŒ 5ï¼šXGBoost + Optuna è¶…å‚æ•°æœç´¢

- **åšäº†ä»€ä¹ˆ**
    - ä½¿ç”¨ TF-IDF + SMOTE å¤„ç†è¿‡çš„æ•°æ®ã€‚
    - ç”¨ Optuna è‡ªåŠ¨æœç´¢ XGBoost çš„è¶…å‚æ•°ï¼ˆn_estimatorsã€learning_rateã€max_depthï¼‰ã€‚
    - åªè®°å½•æœ€ä¼˜ç»“æœåˆ° MLflowã€‚
- **ç›®çš„**
    - æ‰¾åˆ° XGBoost åœ¨å½“å‰æ•°æ®ä¸Šçš„æœ€ä½³é…ç½®ã€‚
- **åŒºåˆ«**
    - å‰é¢æ˜¯ â€œå›ºå®šå‚æ•° + å¯¹æ¯”æ–¹æ³•â€ï¼Œè¿™æ¬¡å¼€å§‹åšÂ **è‡ªåŠ¨åŒ–è¶…å‚æ•°è°ƒä¼˜**ã€‚

---

## ğŸ§ª å®éªŒ 6ï¼šLightGBM + Optuna è¶…å‚æ•°æœç´¢

- **åšäº†ä»€ä¹ˆ**
    - æ€è·¯å’Œå®éªŒ 5 ç±»ä¼¼ï¼Œä½†æ¨¡å‹æ¢æˆ LightGBMã€‚
    - æœç´¢èŒƒå›´æ›´å¤§ï¼ˆn_estimatorsã€num_leavesã€colsample_bytreeã€subsampleã€æ­£åˆ™åŒ–é¡¹ç­‰ï¼‰ã€‚
- **ç›®çš„**
    - éªŒè¯ LightGBM æ˜¯å¦æ¯” XGBoost åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½ã€‚
- **åŒºåˆ«**
    - å’Œå®éªŒ 5 çš„åŒºåˆ«ä¸»è¦æ˜¯Â **æ¨¡å‹æ¡†æ¶ä¸åŒ**ï¼ˆLightGBM vs XGBoostï¼‰ã€‚

---

## ğŸ§ª å®éªŒ 7ï¼šStacking é›†æˆå­¦ä¹ 

- **åšäº†ä»€ä¹ˆ**
    - ç”¨å¤šä¸ªæ¨¡å‹ï¼ˆLightGBMã€Logistic Regressionï¼‰ä½œä¸º base learnersã€‚
    - ç”¨ä¸€ä¸ª meta learnerï¼ˆKNNï¼‰æ•´åˆå‰é¢æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚
- **ç›®çš„**
    - é›†æˆå¤šä¸ªæ¨¡å‹ï¼Œåˆ©ç”¨ä¸åŒæ¨¡å‹çš„äº’è¡¥æ€§æå‡è¡¨ç°ã€‚
- **åŒºåˆ«**
    - å‰ 1â€“6 éƒ½æ˜¯ â€œå•æ¨¡å‹â€ï¼Œè¿™é‡Œæ˜¯Â **æ¨¡å‹é›†æˆ**ï¼Œéš¾åº¦å’Œå¤æ‚åº¦æ›´é«˜ã€‚

---

## ğŸ“Š æ€»ç»“ï¼ˆä¸ƒä¸ªå®éªŒè„‰ç»œï¼‰

1. **å®éªŒ 1â€“2**ï¼šæ¢ç´¢ç‰¹å¾å·¥ç¨‹ â†’ æ–‡æœ¬è¡¨ç¤ºï¼ˆBoW vs TF-IDFï¼Œn-gramï¼Œç‰¹å¾æ•°ï¼‰ã€‚
2. **å®éªŒ 3â€“4**ï¼šè§£å†³æ•°æ®é—®é¢˜ â†’ ç±»åˆ«ä¸å‡è¡¡å¤„ç† + å®éªŒè®°å½•ã€‚
3. **å®éªŒ 5â€“6**ï¼šæ¨¡å‹å±‚é¢å¯¹æ¯” â†’ XGBoost vs LightGBM + è¶…å‚ä¼˜åŒ–ã€‚
4. **å®éªŒ 7**ï¼šè¿›ä¸€æ­¥æå‡ â†’ æ¨¡å‹é›†æˆï¼ˆStackingï¼‰ã€‚

ğŸ‘‰ è¿™ä¸ƒä¸ªå®éªŒæ„æˆäº†ä¸€ä¸ªÂ **å®Œæ•´çš„æœºå™¨å­¦ä¹ æµç¨‹**ï¼š

æ–‡æœ¬è¡¨ç¤º â†’ æ•°æ®å‡è¡¡ â†’ æ¨¡å‹é€‰æ‹©ä¸è°ƒä¼˜ â†’ é›†æˆæå‡ â†’ å®éªŒç®¡ç†ã€‚

**ç¬¬å…­Build ML pipeline using DVC**

### â‘  Data Preprocessingï¼ˆæ•°æ®é¢„å¤„ç†ï¼‰

- æ¸…ç†æ–‡æœ¬ï¼ˆå»åœç”¨è¯ã€ç‰¹æ®Šç¬¦å·ã€lowercaseï¼‰
- æ ‡ç­¾é‡æ˜ å°„ï¼ˆ[-1,0,1] â†’ [2,0,1]ï¼‰
- TF-IDF/BoW å‘é‡åŒ–ï¼ˆngram, max_featuresï¼‰
    
    ğŸ‘‰ å¯¹åº”ä½ å‰å‡ ä¸ªå®éªŒé‡ŒÂ **æ–‡æœ¬è¡¨ç¤ºã€max_features å¯¹æ¯”**ã€‚
    

---

### â‘¡ Model Buildingï¼ˆæ¨¡å‹æ„å»ºï¼‰

- å»ºç«‹åŸºçº¿æ¨¡å‹ï¼ˆLogReg / RF / NB / SVMï¼‰
- å¼•å…¥æ›´å¼ºçš„æ¨¡å‹ï¼ˆXGBoost / LightGBMï¼‰
- ç”¨ Optuna è°ƒä¼˜
    
    ğŸ‘‰ å¯¹åº”å®éªŒÂ **3â€“6**ï¼šåŸºçº¿ â†’ æ”¹è¿› â†’ è°ƒä¼˜ â†’ é›†æˆã€‚
    

---

### â‘¢ Model Evaluation with MLflowï¼ˆæ¨¡å‹è¯„ä¼°ï¼‰

- åœ¨ test set ä¸Šé¢„æµ‹
- è®°å½• accuracyã€F1ã€classification reportã€æ··æ·†çŸ©é˜µ
- æ¯ä¸ªå®éªŒ run éƒ½ log åˆ° MLflow
    
    ğŸ‘‰ å¯¹åº”ä½ å‰é¢æˆªå›¾é‡Œåœ¨ MLflow ä¸­å¯å¯¹æ¯”ä¸åŒå‚æ•°/æ¨¡å‹ç»“æœã€‚
    

---

### â‘£ Model Register with MLflowï¼ˆæ¨¡å‹æ³¨å†Œï¼‰

- æŠŠè¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼ˆæ¯”å¦‚ LightGBM Optuna æœ€ä¼˜å‚æ•°ï¼‰ç”¨ MLflow Registry å­˜æ¡£
- èµ‹äºˆç‰ˆæœ¬å·ï¼ˆv1, v2, â€¦ï¼‰ï¼Œæ–¹ä¾¿éƒ¨ç½²å’Œå›æ»š
    
    ğŸ‘‰ è¿™ä¸€æ­¥æ˜¯å®éªŒå®Œæˆ â†’ ä¸Šçº¿å‰çš„Â **æˆæœå›ºåŒ–**ã€‚
    

**ç»„ä»¶åŒ– ML pipelineï¼ˆç”¨ DVC + MLflow æ­èµ·æ¥ï¼‰**ï¼Œç›®çš„æ˜¯è®©ä½ çš„æ•´ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®åƒä¸€ä¸ªâ€œè½¯ä»¶å·¥ç¨‹é¡¹ç›®â€ä¸€æ ·ï¼Œ**å¯å¤ç°ã€å¯è¿½è¸ªã€å¯æ‰©å±•**ã€‚

å’Œä½ å‰é¢åšçš„ä¸ƒä¸ªå®éªŒç›¸æ¯”ï¼š

- å‰é¢ä¸ƒä¸ªå®éªŒæ›´å¤šæ˜¯â€œæ¢ç´¢æ€§â€ï¼ˆè¯•ä¸åŒçš„å‘é‡åŒ–ã€é‡‡æ ·æ–¹æ³•ã€ç®—æ³•ã€è°ƒå‚ï¼‰ã€‚
- ç°åœ¨åš pipelineï¼Œæ˜¯æŠŠè¿™äº›æ­¥éª¤**å·¥ç¨‹åŒ–**ï¼Œè®©åˆ«äººï¼ˆæˆ–è€…æœªæ¥çš„ä½ è‡ªå·±ï¼‰èƒ½ä¸€é”®å¤ç°ï¼Œå¹¶ä¸”æŒç»­æ”¹è¿›ã€‚

---

### ä¸ºä»€ä¹ˆè¦å¼„è¿™äº›ç»„ä»¶ï¼Ÿ

1. **Data Ingestion Component**
    - è´Ÿè´£æŠŠåŸå§‹æ•°æ®è¯»è¿›æ¥ï¼ˆæ¯”å¦‚ä» CSV/æ•°æ®åº“/æ¥å£ï¼‰ã€‚
    - å¥½å¤„ï¼šæ•°æ®æºå¦‚æœå˜äº†ï¼Œåªè¦æ”¹ ingestionï¼Œä¸ç”¨æ•´ä¸ª pipeline æ”¹ã€‚
2. **Data Preprocessing Component**
    - è´Ÿè´£æ¸…æ´—ã€åˆ†è¯ã€å‘é‡åŒ–ï¼ˆTF-IDFã€BoWï¼‰ã€ç‰¹å¾å·¥ç¨‹ã€‚
    - å¥½å¤„ï¼šä¿è¯æ¯æ¬¡è®­ç»ƒçš„æ•°æ®å¤„ç†ä¸€è‡´ï¼Œé¿å…â€œæ‰‹å·¥è·‘ä¸€æ¬¡å¤„ç†ä¸ä¸€æ ·â€ã€‚
3. **Model Building Component**
    - å®šä¹‰å¹¶è®­ç»ƒæ¨¡å‹ï¼ˆLogistic Regressionã€LightGBMã€Stacking ç­‰ï¼‰ã€‚
    - å¥½å¤„ï¼šæ¨¡å‹æ¢äº†ï¼Œpipeline ä¹Ÿèƒ½è‡ªåŠ¨æ›´æ–°å¹¶è¿½è¸ªã€‚
4. **Model Evaluation Component with MLflow**
    - ç»Ÿä¸€è¯„ä¼°æŒ‡æ ‡ï¼ˆaccuracyã€F1ã€æ··æ·†çŸ©é˜µï¼‰ã€‚
    - ç”¨ MLflow è‡ªåŠ¨è®°å½•æ¯æ¬¡å®éªŒçš„ç»“æœã€‚
    - å¥½å¤„ï¼šå¯ä»¥æ¯”è¾ƒå“ªæ¬¡æ¨¡å‹æ›´å¥½ï¼Œè€Œä¸æ˜¯æ‰‹å·¥è®°ç¬”è®°ã€‚
5. **Model Register Component with MLflow**
    - æŠŠæœ€ä¼˜æ¨¡å‹å­˜åˆ° MLflow çš„ Model Registryã€‚
    - å¥½å¤„ï¼šæ–¹ä¾¿éƒ¨ç½²å’Œç‰ˆæœ¬æ§åˆ¶ï¼ˆæ¯”å¦‚ä½ å¯ä»¥å›æ»šåˆ°æ—§æ¨¡å‹ï¼‰ã€‚
6. **DVC ç®¡ç† pipeline**
    - DVCï¼ˆData Version Controlï¼‰å¯ä»¥åƒ Git ä¸€æ ·ç®¡ç†æ•°æ®ã€æ¨¡å‹å’Œä¸­é—´ç»“æœã€‚
    - å¥½å¤„ï¼šå›¢é˜Ÿåä½œæ—¶ï¼Œä¿è¯æ¯ä¸ªäººè·‘å‡ºæ¥çš„ç»“æœä¸€è‡´ï¼Œæ–¹ä¾¿ CI/CDã€‚

### å‰é¢ 7 ä¸ªå®éªŒ

- **æ ¸å¿ƒç›®æ ‡**ï¼šæ‰¾åˆ°â€œæ•ˆæœå¥½çš„æ¨¡å‹â€ã€‚
- **ç‰¹ç‚¹**ï¼š
    1. æ˜¯Â **æ¢ç´¢æ€§å®éªŒ**Â â†’ æ¯”è¾ƒæ–‡æœ¬è¡¨ç¤ºæ–¹æ³•ï¼ˆBoW / TF-IDFï¼‰ã€ä¸åŒ n-gramã€max_featuresã€‚
    2. ç ”ç©¶Â **ç±»åˆ«ä¸å‡è¡¡çš„å¤„ç†ç­–ç•¥**ï¼ˆSMOTEã€undersamplingã€class weight ç­‰ï¼‰ã€‚
    3. æ¯”è¾ƒÂ **ä¸åŒç®—æ³•**ï¼ˆRandom Forestã€SVMã€LightGBMã€XGBoost ç­‰ï¼‰ï¼Œå†ç”¨ Optuna è°ƒå‚ã€‚
    4. å°è¯•Â **é›†æˆæ–¹æ³•**ï¼ˆStackingã€Boostingï¼‰æå‡æ€§èƒ½ã€‚
    5. æ¯æ¬¡å®éªŒéƒ½ç”¨ MLflow è®°å½•æŒ‡æ ‡ï¼Œä¸»è¦æ˜¯â€œå®éªŒç®¡ç†â€ã€‚

ğŸ‘‰ æœ¬è´¨ï¼šè¿™æ˜¯Â **å»ºæ¨¡é˜¶æ®µçš„æ¢ç´¢**ï¼Œä½ åœ¨å›ç­”â€œå“ªä¸ªæ¨¡å‹å’Œé…ç½®æ›´å¥½ï¼Ÿâ€

---

### ç°åœ¨çš„ DVC + MLflow Pipeline

- **æ ¸å¿ƒç›®æ ‡**ï¼šè®©å®éªŒÂ **å·¥ç¨‹åŒ–ã€å¯å¤ç°ã€å¯éƒ¨ç½²**ã€‚
- **ç‰¹ç‚¹**ï¼š
    1. **ç»„ä»¶åŒ–**Â â†’ åˆ†æˆ Data Ingestionã€Preprocessingã€Model Buildingã€Evaluationã€Registerã€‚
    2. **å¯å¤ç°**Â â†’ ä¸ç®¡ä½ è¿˜æ˜¯åˆ«äººï¼Œä¸‹ä¸ªæœˆå†è·‘ä¸€éï¼Œç»“æœå®Œå…¨ä¸€æ ·ã€‚
    3. **å¯è¿½è¸ª**Â â†’ DVC è·Ÿè¸ªæ•°æ®/æ¨¡å‹å˜åŒ–ï¼ŒMLflow è·Ÿè¸ªå®éªŒç»“æœã€‚
    4. **å¯éƒ¨ç½²**Â â†’ æœ€ä¼˜æ¨¡å‹ç›´æ¥è¿›å…¥ MLflow Model Registryï¼Œæ–¹ä¾¿ä¸Šçº¿/å›æ»šã€‚
    5. **å¯æ‰©å±•**Â â†’ å¦‚æœä»¥åæ¢æ•°æ®ã€åŠ æ–°æ¨¡å‹ï¼Œä¸éœ€è¦æ¨å€’é‡æ¥ï¼Œåªè¦æ›´æ–°å¯¹åº”ç»„ä»¶ã€‚

ğŸ‘‰ æœ¬è´¨ï¼šè¿™æ˜¯Â **MLOps é˜¶æ®µçš„è½åœ°**ï¼Œä½ åœ¨å›ç­”â€œæ€ä¹ˆè®©å¥½çš„æ¨¡å‹èƒ½ç¨³å®šå¤ç°ã€ä¸Šçº¿å’Œè¿­ä»£ï¼Ÿâ€

---

### ç®€å•æ¯”å–»

- **7 ä¸ªå®éªŒ**Â = åœ¨å¨æˆ¿é‡Œå°ä¸åŒçš„èœè°±ï¼Œæ‰¾åˆ°å“ªé“èœæœ€å¥½åƒã€‚
- **DVC + MLflow pipeline**Â = æŠŠè¿™é“èœå†™æˆé¤å…çš„ SOPï¼ˆæ ‡å‡†åŒ–æµç¨‹ï¼‰ï¼Œä¿è¯æ¯æ¬¡ç«¯å‡ºæ¥çš„èœéƒ½ä¸€æ ·ï¼Œè¿˜èƒ½éšæ—¶æ¢æ–°èœå•ã€‚

### 1.Â **DVC (Data Version Control)**

- **æ˜¯ä»€ä¹ˆ**ï¼š
    
    ç±»ä¼¼äºÂ **Git**ï¼Œä½†ä¸“é—¨ç”¨æ¥ç®¡ç†Â **æ•°æ®å’Œæ¨¡å‹æ–‡ä»¶**ã€‚
    
- **ä¸ºä»€ä¹ˆè¦ç”¨**ï¼š
    - Git å¯ä»¥ç®¡ä»£ç ï¼Œä½†å‡ ç™¾ MB/GB çš„æ•°æ®ã€æ¨¡å‹ä¸å¥½ç®¡ã€‚
    - DVC å¯ä»¥åƒ Git ä¸€æ ·æ‰“ tagã€åšç‰ˆæœ¬å›æº¯ï¼ˆæ¯”å¦‚ï¼šå›åˆ°ä¸Šä¸ªæœˆçš„æ•°æ®ã€æ¨¡å‹ç‰ˆæœ¬ï¼‰ã€‚
    - æ–¹ä¾¿å›¢é˜Ÿåä½œï¼šåˆ«äººä¸€é”®Â `dvc pull`Â å°±èƒ½è·å¾—åŒæ ·çš„æ•°æ®/æ¨¡å‹ã€‚
- **åœºæ™¯**ï¼š
    - è®°å½•æ•°æ®é›†çš„å˜åŒ–ï¼ˆv1 â†’ v2 â†’ v3ï¼‰ã€‚
    - è·Ÿè¸ªè®­ç»ƒå¾—åˆ°çš„æ¨¡å‹ï¼ˆmodel_v1.pkl, model_v2.pklï¼‰ã€‚
    - åœ¨ pipeline ä¸­å®šä¹‰æ•°æ® â†’ é¢„å¤„ç† â†’ è®­ç»ƒ â†’ è¯„ä¼° â†’ æ³¨å†Œçš„Â **æ­¥éª¤ä¾èµ–**ã€‚

---

### 2.Â **YAML æ–‡ä»¶**

- **æ˜¯ä»€ä¹ˆ**ï¼šä¸€ç§é…ç½®æ–‡ä»¶æ ¼å¼ï¼ˆåƒ JSONï¼Œä½†æ›´ç®€æ´ï¼‰ã€‚
- **ä¸ºä»€ä¹ˆè¦ç”¨**ï¼š
    
    åœ¨ ML pipeline é‡Œï¼Œç”¨ YAML æ–‡ä»¶æ¥å®šä¹‰Â **æ­¥éª¤ã€ä¾èµ–ã€è¾“å…¥è¾“å‡º**ã€‚
    
- **ä¾‹å­**ï¼šDVC çš„Â `dvc.yaml`Â æ–‡ä»¶å¯èƒ½é•¿è¿™æ ·ï¼š
    
    ```yaml
    stages:
      preprocess:
        cmd: python src/preprocess.py
        deps:
          - data/raw/reddit.csv
          - src/preprocess.py
        outs:
          - data/processed/clean_reddit.csv
    
      train:
        cmd: python src/train.py
        deps:
          - data/processed/clean_reddit.csv
          - src/train.py
        outs:
          - models/random_forest.pkl
    
    ```
    
    ğŸ‘‰ å«ä¹‰ï¼š
    
    - å¦‚æœåŸå§‹æ•°æ®æˆ–Â `preprocess.py`Â æ”¹äº†ï¼ŒDVC ä¼šè‡ªåŠ¨é‡è·‘Â **preprocess**Â å’ŒÂ **train**ã€‚
    - å¦‚æœåªæœ‰è®­ç»ƒä»£ç æ”¹äº†ï¼Œå°±åªé‡è·‘Â **train**ã€‚
    - ç›¸å½“äºä¸€ä¸ªÂ **è‡ªåŠ¨åŒ–çš„å®éªŒæµæ°´çº¿**ã€‚

---

### 3.Â **PKL æ–‡ä»¶**

- **æ˜¯ä»€ä¹ˆ**ï¼šPython çš„åºåˆ—åŒ–æ–‡ä»¶ï¼ˆPickle æ ¼å¼ï¼‰ã€‚
- **ä¸ºä»€ä¹ˆè¦ç”¨**ï¼š
    - è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆæ¯”å¦‚ RandomForestClassifierï¼‰ä¸èƒ½ç›´æ¥ä¿å­˜ä¸ºÂ `.csv`ï¼Œæ‰€ä»¥ç”¨ Pickle ä¿å­˜æˆÂ `.pkl`Â æ–‡ä»¶ã€‚
    - ä¸‹æ¬¡é¢„æµ‹æ—¶ç›´æ¥Â `joblib.load("model.pkl")`Â æˆ–Â `pickle.load()`Â å°±èƒ½åŠ è½½æ¨¡å‹ï¼Œè€Œä¸ç”¨é‡æ–°è®­ç»ƒã€‚
- **åœºæ™¯**ï¼š
    - æ¨¡å‹ä¸Šçº¿éƒ¨ç½²ã€‚
    - ä¿å­˜/åŠ è½½ç‰¹å¾å·¥ç¨‹å¯¹è±¡ï¼ˆå¦‚Â `TfidfVectorizer.pkl`ï¼‰ã€‚

---

### 4.Â **ä¸ºä»€ä¹ˆåé¢è¿˜è¦å¼„ MLflowï¼Ÿ**

- DVC è§£å†³çš„æ˜¯ï¼š**æ•°æ® & è®­ç»ƒè¿‡ç¨‹çš„å¯å¤ç°**ã€‚
- ä½†å®éªŒè¿˜æœ‰æ›´å¤æ‚çš„éœ€æ±‚ï¼š
    - ä¸åŒå‚æ•°ã€æ¨¡å‹æ•ˆæœè¦è®°å½•ï¼ˆAccuracy, F1, æ··æ·†çŸ©é˜µï¼‰ã€‚
    - è¦æœ‰ä¸€ä¸ªåœ°æ–¹ç®¡ç†æ‰€æœ‰å®éªŒçš„ç»“æœã€‚
    - è¦èƒ½æŠŠæœ€ä¼˜æ¨¡å‹Â **æ³¨å†Œ/éƒ¨ç½²**ï¼Œæ–¹ä¾¿ç”Ÿäº§ç¯å¢ƒè°ƒç”¨ã€‚
- **MLflow å°±æ˜¯åšå®éªŒç®¡ç† + æ¨¡å‹ç®¡ç†çš„å·¥å…·**ï¼š
    - `mlflow.log_param()`Â â†’ è®°å½•å‚æ•°ã€‚
    - `mlflow.log_metric()`Â â†’ è®°å½•ç»“æœã€‚
    - `mlflow.sklearn.log_model()`Â â†’ ä¿å­˜æ¨¡å‹ï¼Œå¹¶æ¨åˆ°Â **Model Registry**ã€‚

ğŸ‘‰ ç»“åˆèµ·æ¥ï¼š

- **DVC**Â = æ•°æ®/è¿‡ç¨‹çš„ Git
- **MLflow**Â = å®éªŒ & æ¨¡å‹çš„æ—¥å¿—ç°¿/ä»“åº“
- **PKL**Â = æ¨¡å‹å­˜æ¡£æ ¼å¼
- **YAML**Â = å®šä¹‰ pipeline çš„é…ç½®è„šæœ¬

---

âœ… æ€»ç»“ä¸€å¥ï¼š

å‰é¢çš„ 7 ä¸ªå®éªŒåªæ˜¯â€œæ‰¾åˆ°å¥½æ¨¡å‹â€ï¼Œ

DVC + YAML + PKL + MLflow = æŠŠè¿™ä¸ªæ¨¡å‹åšæˆÂ **æ ‡å‡†åŒ–å·¥ç¨‹æµæ°´çº¿**ï¼Œä¿è¯ä»»ä½•äººã€ä»»ä½•æ—¶å€™éƒ½èƒ½å¤ç°å’Œä¸Šçº¿ã€‚

### ä¸‰è€…çš„å…³ç³»

- **DVC**ï¼šæ˜¯æ•´ä¸ªé¡¹ç›®çš„â€œæµç¨‹ç®¡ç† + ç‰ˆæœ¬æ§åˆ¶â€å·¥å…·ã€‚
- **YAML**ï¼šæ˜¯ DVC ç”¨æ¥å®šä¹‰æµç¨‹çš„é…ç½®æ–‡ä»¶ï¼Œè§„å®šæ•°æ®æµå’Œäº§ç‰©ã€‚
- **PKL**ï¼šæ˜¯æµç¨‹çš„äº§ç‰©ä¹‹ä¸€ï¼Œä¿å­˜çš„å°±æ˜¯è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚

ğŸ‘‰ å¯ä»¥è¿™æ ·ç†è§£ï¼š

- **DVC = ç®¡ç†è€…**
- **YAML = ç®¡ç†è€…æ‰‹é‡Œçš„æµç¨‹å›¾**
- **PKL = æµç¨‹äº§å‡ºçš„æˆå“ï¼ˆæ¨¡å‹æ–‡ä»¶ï¼‰**

å»ºå¥½mlflowäº†

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2025.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2026.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2027.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2028.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2029.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2030.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2031.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2032.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2033.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2034.png)

[https://www.notion.so](https://www.notion.so)

AIzaSyA7kKnxD4jF9cKOFhtMM0y4WgoJF5Tl108

cicd

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2035.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2036.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2037.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2038.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2039.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2040.png)

```markdown
# AWS-CICD-Deployment-with-Github-Actions

## 1. Login to AWS console.

## 2. Create IAM user for deployment

	#with specific access(you)
	0. iam(æœ‰access key)
	1. EC2 access : It is virtual machine !
(ç„¶åå°±ä¼šè¿›å…¥mahineï¼‰
	2. ECR: Elastic Container registry to save your docker image in aws
	
	294892597101.dkr.ecr.us-east-1.amazonaws.com/mlops-pipeline

	#Description: About the deployment

	1. Build docker image of the source code

	2. Push your docker image to ECR

	3. Launch Your EC2 

	4. Pull Your image from ECR in EC2

	5. Lauch your docker image in EC2

	#Policy:

	1. AmazonEC2ContainerRegistryFullAccess

	2. AmazonEC2FullAccess

	
## 3. Create ECR repo to store/save docker image
    - Save the URI: 
    294892597101.dkr.ecr.us-east-1.amazonaws.com/mlops-pipeline

	
## 4. Create EC2 machine (Ubuntu) 

## 5. Open EC2 and Install docker in EC2 Machine:
	
	
	#optinal

	sudo apt-get update -y

	sudo apt-get upgrade
	
	#required

	curl -fsSL https://get.docker.com -o get-docker.sh

	sudo sh get-docker.sh

	sudo usermod -aG docker ubuntu

	newgrp docker
	
# 6. Configure EC2 as self-hosted runner:
    setting>actions>runner>new self hosted runner> choose os> then run command one by one
	(å°±æ˜¯å»githubæŠŠè¯­å¥ç»™å¼„ä¸‹æ¥ )

# 7. Setup github secrets:

    AWS_ACCESS_KEY_ID=

    AWS_SECRET_ACCESS_KEY=

    AWS_REGION = us-east-1

    AWS_ECR_LOGIN_URI = demo>>  566373416292.dkr.ecr.ap-south-1.amazonaws.com

    ECR_REPOSITORY_NAME = simple-app

```

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2041.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2042.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2043.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2044.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2045.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2046.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2047.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2048.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2049.png)

52.71.42.112

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2050.png)

![image.png](%E4%BD%BF%E7%94%A8%20Python%E3%80%81AWS%E3%80%81Docker%20%E7%9A%84%20MLOps%20%E7%AE%A1%E9%81%93%20%E2%80%93%20YouTube%20%E8%A7%82%E4%BC%97%E6%83%85%E7%BB%AA%20276307fdbf47807e8e4ac3141fa0821c/image%2051.png)